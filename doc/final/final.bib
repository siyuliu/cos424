@article{Boykov2006,
 author = {Boykov, Yuri and Funka-Lea, Gareth},
 title = {Graph Cuts and Efficient N-D Image Segmentation},
 journal = {Int. J. Comput. Vision},
 issue_date = {November  2006},
 volume = {70},
 number = {2},
 month = nov,
 year = {2006},
 issn = {0920-5691},
 pages = {109--131},
 numpages = {23},
 url = {http://dx.doi.org/10.1007/s11263-006-7934-5},
 doi = {10.1007/s11263-006-7934-5},
 acmid = {1147801},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
} 

@article{Besag1986statisticalanalysis,
    author = {J. Besag},
    title = {On the statistical analysis of dirty pictures (with discussion)},
    journal = {Journal of Royal Statistical Society, Series B},
    year = {1986},
    volume = {48},
    number = {3},
    pages = {259--302}
}

@article{Comaniciu1997featurespace,
    author = {D. Comaniciu and P. Meer},
    title = {Robust analysis of feature spaces: color image segmentation},
    journal = {Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},
    year = {1997},
    pages = {750--755}
}

@article{Comaniciu1999meanshift,
    author = {D. Comaniciu and P. Meer},
    title = {Mean shift analysis and application},
    journal = {Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},
    year = {1999},
    pages = {1197--1203}
}

@article{Comaniciu2002robustapproach,
    author = {D. Comaniciu and P. Meer},
    title = {Mean shift: A robust approach toward feature space analysis},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    volume = {24},
    year = {2002},
    pages = {603--619}
}

@article{Carson2002bolbworld,
    author = {C. Carson and S. Belongie and H. Greenspan and J. Malik},
    title = {Blobworld: Image segmentation using expectation-maximization and its application to image querying},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    volume = {24},
    number = {8},
    year = {2002},
    pages = {1026--1038}
}

@article{Caselles1995geodesic,
    author = {Vicent Caselles and Ron Kimmel and Guillermo Sapiro},
    title = {Geodesic Active Contours},
    journal = {International Journal of Computer Vision},
    year = {1995},
    volume = {22},
    pages = {61--79}
}

@article{Freeman2000lowlevel,
    author = {W. Freeman and E. Pasztor and O. Carmichael},
    title = {Learning low-level vision},
    journal = {International Journal of Computer Vision},
    year = {2000},
    volume = {40},
    number = {1},
    pages = {25--47}
}

@article{Isard1998condensation,
    author = {Michael Isard and Andrew Blake},
    title = {CONDENSATION - conditional density propagation for visual tracking},
    journal = {International Journal of Computer Vision},
    year = {1998},
    volume = {29},
    pages = {5--28}
}

@article{Kass1988snakes,
    author = {Michael Kass and Andrew Witkin and Demetri Terzopoulos},
    title = {Snakes: Active contour models},
    journal = {INTERNATIONAL JOURNAL OF COMPUTER VISION},
    year = {1988},
    volume = {1},
    number = {4},
    pages = {321--331}
}

@article{Kolmogorov2006messagepassing,
    author = {V. Kolmogorov},
    title = {Covergent tree-reweighted message passing for energy minimization},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    year = {2006},
    volume = {28},
    number = {10},
    pages = {1568--1583}
}

@article{Lowe2004sift,
    author = {D. G. Lowe},
    title = {Distinctive Image Features from Scale-Invariant features},
    journal = {International Journal of Computer Vision},
    year = {2004},
}

@inproceedings{musialski2012survey,
    booktitle = {EUROGRAPHICS 2012 State of the Art Reports},
    citeulike-article-id = {10528236},
    citeulike-linkout-0 = {http://www.cg.tuwien.ac.at/research/publications/2012/musialski-2012-sur/},
    keywords = {city, reconstruction},
    posted-at = {2012-04-04 18:06:25},
    priority = {5},
    publisher = {Eurographics Association},
    title = {{A Survey of Urban Reconstruction}},
    year = {2012}
}

@article{Shi1997normalizedcuts,
    author = {J. Shi and J. Malik},
    title = {Normalized cuts and image segmentation},
    journal = {Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},
    year = {1997},
    pages = {731--737}
}

@article{Wu1993optimalgraph,
    author = {Z. Wu and R. Leahy},
    title = {An optimal graph theoretic approach to data clustering: Theory and its application to image segmentation},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    volume = {11},
    year = {1993},
    pages = {1101--1113}
}

@book{Therrien1989Decision,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Therrien, Charles W.},
    citeulike-article-id = {10525083},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=61950},
    comment = {When both the prior and likelihood distributions are known, the best result is achieved by maximizing a Bayes criterion according to Bayes Statistics.},
    isbn = {0-471-83102-6},
    keywords = {baysian},
    posted-at = {2012-04-03 22:23:45},
    priority = {2},
    publisher = {John Wiley \&amp; Sons, Inc.},
    title = {{Decision estimation and classification: an introduction to pattern recognition and related topics}},
    year = {1989}
}

@article{Jaynes1982Rationale,
    abstract = {{We discuss the relations between maximum-entropy (MAXENT) and other methods of spectral analysis such as the Schuster, Blackman-Tukey, maximum-likelihood, Bayesian, and Autoregressive (AR, ARMA, or ARIMA) models, emphasizing that they are not in conflict, but rather are appropriate in different problems. We conclude that: 1) "Orthodox" sampling theory methods are useful in problems where we have a known model (sampling distribution) for the properties of the noise, but no appreciable prior information about the quantities being estimated. 2) MAXENT is optimal in problems where we have prior information about multiplicities, but no noise. 3) The full Bayesian solution includes both of these as special cases and is needed in problems where we have both prior information and noise. 4) AR models are in one sense a special case of MAXENT, but in another sense they are ubiquitous in all spectral analysis problems with discrete time series. 5) Empirical methods such as Blackman-Tukey, which do not invoke even a likelihood function, are useful in the preliminary, exploratory phase of a problem where our knowledge is sufficient to permit intuitive judgments about how to organize a calculation (smoothing, decimation, windows, prewhitening, padding with zeroes, etc.) but insufficient to set up a quantitative model which would do the proper things for us automatically and optimally.}},
    author = {Jaynes, E. T.},
    booktitle = {Proceedings of the IEEE},
    citeulike-article-id = {2447964},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/PROC.1982.12425},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1456693},
    day = {28},
    issn = {0018-9219},
    journal = {Proceedings of the IEEE},
    keywords = {maximum\_entropy},
    month = jun,
    number = {9},
    pages = {939--952},
    posted-at = {2012-04-03 22:16:49},
    priority = {3},
    title = {{On the rationale of maximum-entropy methods}},
    volume = {70},
    year = {1982}
}

@article{Stockman1977Equivalence,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Stockman, G. C. and Agrawala, A. K.},
    citeulike-article-id = {10525030},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=359882},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/359863.359882},
    issn = {0001-0782},
    journal = {Commun. ACM},
    keywords = {edge, hough, line, optimization},
    month = nov,
    number = {11},
    pages = {820--822},
    posted-at = {2012-04-03 22:07:59},
    priority = {2},
    publisher = {ACM},
    title = {{Equivalence of Hough curve detection to template matching}},
    volume = {20},
    year = {1977}
}

@phdthesis{Roberts1963Machine,
    author = {Roberts, Lawrence G.},
    citeulike-article-id = {8907132},
    citeulike-linkout-0 = {http://www.packet.cc/files/mach-per-3D-solids.html},
    citeulike-linkout-1 = {http://www.packet.cc/files/mach-per-3D-solids.html},
    comment = {(private-note)Pioneer vision system
---=note-separator=---
(private-note)pose estimation are performed using the simplest least squares fitting},
    posted-at = {2012-04-03 22:00:45},
    priority = {2},
    publisher = {Massachusetts Institute of Technology},
    school = {Massachusetts Institute of Technology. Dept. of Electrical Engineering},
    title = {{Machine perception of three-dimensional solids}},
    year = {1963}
}

@article{Shi2000Normalized,
    abstract = {{We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We applied this approach to segmenting static images, as well as motion sequences, and found the results to be very encouraging}},
    address = {Washington, DC, USA},
    author = {Shi, Jianbo and Malik, J.},
    booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    citeulike-article-id = {520154},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=351611},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/34.868688},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/34.868688},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=868688},
    day = {06},
    issn = {01628828},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {cos424, segmentation},
    month = aug,
    number = {8},
    pages = {888--905},
    posted-at = {2012-04-03 15:38:18},
    priority = {2},
    publisher = {IEEE},
    title = {{Normalized cuts and image segmentation}},
    volume = {22},
    year = {2000}
}

@article{Besag74,
    abstract = {{The formulation of conditional probability models for finite systems of spatially interacting random variables is examined. A simple alternative proof of the Hammersley-Clifford theorem is presented and the theorem is then used to construct specific spatial schemes on and off the lattice. Particular emphasis is placed upon practical applications of the models in plant ecology when the variates are binary or Gaussian. Some aspects of infinite lattice Gaussian processes are discussed. Methods of statistical analysis for lattice schemes are proposed, including a very flexible coding technique. The methods are illustrated by two numerical examples. It is maintained throughout that the conditional probability approach to the specification and analysis of spatial interaction is more attractive than the alternative joint probability approach.}},
    author = {Besag, Julian},
    citeulike-article-id = {2075912},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/2984812},
    citeulike-linkout-1 = {http://www.jstor.org/stable/2984812},
    journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
    keywords = {cos424, mrf},
    number = {2},
    pages = {192--236},
    posted-at = {2012-04-03 03:37:19},
    priority = {4},
    publisher = {Blackwell Publishing},
    title = {{Spatial Interaction and the Statistical Analysis of Lattice Systems}},
    volume = {36},
    year = {1974}
}

@inproceedings{Sutton2005Piecewise,
    abstract = {{For many large undirected models that arise in real-world applications, exact maximumlikelihood training is intractable, because it requires computing marginal distributions of the model. Conditional training is even more difficult, because the partition function depends not only on the parameters, but also on the observed input, requiring repeated inference over each training example. An appealing idea for such models is to independently train a local undirected classifier over each clique, afterwards combining the learned weights into a single global model. In this paper, we show that this piecewise method can be justified as minimizing a new family of upper bounds on the log partition function. On three natural-language data sets, piecewise training is more accurate than pseudolikelihood, and often performs comparably to global training using belief propagation. 1}},
    author = {Sutton, Charles and Mccallum, Andrew},
    booktitle = {In Proc. of UAI},
    citeulike-article-id = {8741812},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.152.5491},
    keywords = {graphical\_model},
    posted-at = {2012-04-01 02:20:59},
    priority = {2},
    title = {{Piecewise training of undirected models}},
    year = {2005}
}

@article{Malik2001Contour,
    abstract = {{This paper provides an algorithm for partitioning grayscale images into disjoint regions of coherent brightness and texture. Natural images contain both textured and untextured regions, so the cues of contour and texture differences are exploited simultaneously. Contours are treated in the intervening contour framework, while texture is analyzed using textons. Each of these cues has a domain of applicability, so to facilitate cue combination we introduce a gating operator based on the texturedness of the neighborhood at a pixel. Having obtained a local measure of how likely two nearby pixels are to belong to the same region, we use the spectral graph theoretic framework of normalized cuts to find partitions of the image into regions of coherent texture and brightness. Experimental results on a wide range of images are shown.}},
    address = {Hingham, MA, USA},
    author = {Malik, Jitendra and Belongie, Serge and Leung, Thomas and Shi, Jianbo},
    citeulike-article-id = {985069},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=543016},
    citeulike-linkout-1 = {http://dx.doi.org/10.1023/A:1011174803800},
    citeulike-linkout-2 = {http://www.springerlink.com/content/m7548w2t208n8655},
    day = {1},
    issn = {0920-5691},
    journal = {Int. J. Comput. Vision},
    keywords = {contour, segmentation, texture},
    month = jun,
    number = {1},
    pages = {7--27},
    posted-at = {2012-04-01 02:04:04},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {{Contour and Texture Analysis for Image Segmentation}},
    volume = {43},
    year = {2001}
}

@article{Arbelaez2011Contour,
    abstract = {{This paper investigates two fundamental problems in computer vision: contour detection and image segmentation. We present state-of-the-art algorithms for both of these tasks. Our contour detector combines multiple local cues into a globalization framework based on spectral clustering. Our segmentation algorithm consists of generic machinery for transforming the output of any contour detector into a hierarchical region tree. In this manner, we reduce the problem of image segmentation to that of contour detection. Extensive experimental evaluation demonstrates that both our contour detection and segmentation methods significantly outperform competing algorithms. The automatically generated hierarchical segmentations can be interactively refined by user-specified annotations. Computation at multiple image resolutions provides a means of coupling our system to recognition applications.}},
    address = {Los Alamitos, CA, USA},
    author = {Arbeláez, P. and Maire, M. and Fowlkes, C. and Malik, J.},
    citeulike-article-id = {7795237},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/TPAMI.2010.161},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/TPAMI.2010.161},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5557884},
    issn = {0162-8828},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {contour, hierarchical, segmentation},
    month = may,
    number = {5},
    pages = {898--916},
    posted-at = {2012-03-31 22:12:05},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {{Contour Detection and Hierarchical Image Segmentation}},
    volume = {33},
    year = {2011}
}

@article{Zhang2001Segmentation,
    abstract = {{The finite mixture (FM) model is the most commonly used model for statistical segmentation of brain magnetic resonance (MR) images because of its simple mathematical form and the piecewise constant nature of ideal brain MR images. However, being a histogram-based model, the FM has an intrinsic limitation-no spatial information is taken into account. This causes the FM model to work only on well-defined images with low levels of noise; unfortunately, this is often not the the case due to artifacts such as partial volume effect and bias field distortion. Under these conditions, FM model-based methods produce unreliable results. Here, the authors propose a novel hidden Markov random field (HMRF) model, which is a stochastic process generated by a MRF whose state sequence cannot be observed directly but which can be indirectly estimated through observations. Mathematically, it can be shown that the FM model is a degenerate version of the HMRF model. The advantage of the HMRF model derives from the way in which the spatial information is encoded through the mutual influences of neighboring sites. Although MRF modeling has been employed in MR image segmentation by other researchers, most reported methods are limited to using MRF as a general prior in an FM model-based approach. To fit the HMRF model, an EM algorithm is used. The authors show that by incorporating both the HMRF model and the EM algorithm into a HMRF-EM framework, an accurate and robust segmentation can be achieved. More importantly, the HMRF-EM framework can easily be combined with other techniques. As an example, the authors show how the bias field correction algorithm of Guillemaud and Brady (1997) can be incorporated into this framework to achieve a three-dimensional fully automated approach for brain MR image segmentation.}},
    author = {Zhang, Y. and Brady, M. and Smith, S.},
    booktitle = {Medical Imaging, IEEE Transactions on},
    citeulike-article-id = {1881652},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/42.906424},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=906424},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/11293691},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=11293691},
    institution = {John Radcliffe Hosp., Oxford Univ., UK},
    issn = {0278-0062},
    journal = {Medical Imaging, IEEE Transactions on},
    keywords = {em, mrf},
    month = jan,
    number = {1},
    pages = {45--57},
    pmid = {11293691},
    posted-at = {2012-03-31 00:19:11},
    priority = {2},
    publisher = {IEEE},
    title = {{Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm}},
    volume = {20},
    year = {2001}
}

@article{Rother2004GrabCut,
    abstract = {{The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for "border matting" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools.}},
    address = {New York, NY, USA},
    author = {Rother, Carsten and Kolmogorov, Vladimir and Blake, Andrew},
    citeulike-article-id = {126703},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1015706.1015720},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1015706.1015720},
    issn = {0730-0301},
    journal = {ACM Trans. Graph.},
    keywords = {graph\_cut, mrf},
    month = aug,
    number = {3},
    pages = {309--314},
    posted-at = {2012-03-31 00:08:51},
    priority = {2},
    publisher = {ACM},
    title = {{"GrabCut": interactive foreground extraction using iterated graph cuts}},
    volume = {23},
    year = {2004}
}

@article{Kolmogorov2004What,
    abstract = {{In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization problems in computer vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the energy. Yet, because these graph constructions are complex and highly specific to a particular energy function, graph cuts have seen limited application to date. In this paper, we give a characterization of the energy functions that can be minimized by graph cuts. Our results are restricted to functions of binary variables. However, our work generalizes many previous constructions and is easily applicable to vision problems that involve large numbers of labels, such as stereo, motion, image restoration, and scene reconstruction. We give a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be written as a sum of terms containing three or fewer binary variables. We also provide a general-purpose construction to minimize such an energy function. Finally, we give a necessary condition for any energy function of binary variables to be minimized by graph cuts. Researchers who are considering the use of graph cuts to optimize a particular energy function can use our results to determine if this is possible and then follow our construction to create the appropriate graph. A software implementation is freely available.}},
    address = {Los Alamitos, CA, USA},
    author = {Kolmogorov, V. and Zabin, R.},
    booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    citeulike-article-id = {896086},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=960297},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/TPAMI.2004.1262177},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/TPAMI.2004.1262177},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1262177},
    institution = {Dept. of Comput. Sci., Cornell Univ., Ithaca, NY, USA},
    issn = {0162-8828},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {energy\_minimization, graph\_cut},
    month = feb,
    number = {2},
    pages = {147--159},
    posted-at = {2012-03-31 00:08:28},
    priority = {2},
    publisher = {IEEE},
    title = {{What energy functions can be minimized via graph cuts?}},
    volume = {26},
    year = {2004}
}

@article{Johnson2006NPcompleteness,
    abstract = {{This is the 25th edition of a column that covers new developments in the theory of NP-completeness. The presentation is modeled on that which M. R. Garey and I used in our book Computers and Intractability: A Guide to the Theory of NP-Completeness, W. H. Freeman \& Co., New York, 1979, hereinafter referred to as  ” [G\&J].” Previous columns, the first 23 of which appeared in Journal of Algorithms, will be referred to by a combination of their sequence number and year of appearance, for example, [Col 1, 1981]. Full bibliographic details on the previous columns as well as downloadable unofficial versions of them can be found at http://www.reseach.att.com/\~{}dsj/columns/. This edition of the column discusses the wide range of lower bounds on approximation guarantees for NP-hard optimization problems both in their functional forms and in the hypotheses on which they depend.}},
    address = {New York, NY, USA},
    author = {Johnson, David S.},
    citeulike-article-id = {9924583},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1159892.1159901},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1159892.1159901},
    issn = {1549-6325},
    journal = {ACM Trans. Algorithms},
    keywords = {approximation, limit, npc},
    month = jul,
    number = {3},
    pages = {473--489},
    posted-at = {2012-03-29 05:43:52},
    priority = {2},
    publisher = {ACM},
    title = {{The NP-completeness column: The many limits on approximation}},
    volume = {2},
    year = {2006}
}

@article{McInerney2000Tsnakes,
    abstract = {{We present a new class of deformable contours (snakes) and apply them to the segmentation of medical images. Our snakes are defined in terms of an affine cell image decomposition (ACID). The 'snakes in ACID' framework significantly extends conventional snakes, enabling topological flexibility among other features. The resulting topology adaptive snakes, or 'T-snakes', can be used to segment some of the most complex-shaped biological structures from medical images in an efficient and highly automated manner.}},
    author = {McInerney, Tim and Terzopoulos, Demetri},
    citeulike-article-id = {10488443},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S1361-8415(00)00008-6},
    issn = {13618415},
    journal = {Medical Image Analysis},
    keywords = {adaptive, snakes},
    month = jun,
    number = {2},
    pages = {73--91},
    posted-at = {2012-03-23 01:33:23},
    priority = {2},
    title = {{T-snakes: Topology adaptive snakes}},
    volume = {4},
    year = {2000}
}

@article{Cootes1995Active,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Cootes, T. F. and Taylor, C. J. and Cooper, D. H. and Graham, J.},
    citeulike-article-id = {1158393},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=206547},
    citeulike-linkout-1 = {http://dx.doi.org/10.1006/cviu.1995.1004},
    citeulike-linkout-2 = {http://www.scopus.com/record/display.url?view=extended\&origin=resultslist\&eid=2-s2.0-0029182228},
    citeulike-linkout-3 = {http://www.sciencedirect.com/science/article/B6WCX-45NJT56-1K/2/1933a32b2a89e4c3f032ba0718f4ef03},
    comment = {(private-note)A model should only be able to deform in ways characteristic of the class of objects it represents.},
    issn = {1077-3142},
    journal = {Comput. Vis. Image Underst.},
    keywords = {active\_shape\_model, segmentation},
    month = jan,
    number = {1},
    pages = {38--59},
    posted-at = {2012-03-22 23:38:25},
    priority = {5},
    publisher = {Elsevier Science Inc.},
    title = {{Active shape models - their training and application}},
    volume = {61},
    year = {1995}
}

@article{Estrada2009Benchmarking,
    abstract = {{We present a thorough quantitative evaluation of four image segmentation algorithms on images from the Berkeley Segmentation Database. The algorithms are evaluated using an efficient algorithm for computing precision and recall with regard to human ground-truth boundaries. We test each segmentation method over a representative set of input parameters, and present tuning curves that fully characterize algorithm performance over the complete image database. We complement the evaluation on the BSD with segmentation results on synthetic images. The results reported here provide a useful benchmark for current and future research efforts in image segmentation.}},
    address = {Hingham, MA, USA},
    author = {Estrada, Francisco J. and Jepson, Allan D.},
    citeulike-article-id = {4687053},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1612884},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s11263-009-0251-z},
    citeulike-linkout-2 = {http://www.springerlink.com/content/h283216366r1h6n7},
    comment = {(private-note)The ROC comparison between human and algorithms is interesting. There is not curve for human ROC},
    day = {1},
    issn = {0920-5691},
    journal = {Int. J. Comput. Vision},
    keywords = {segmentation, survey},
    month = nov,
    number = {2},
    pages = {167--181},
    posted-at = {2012-03-22 21:10:43},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {{Benchmarking Image Segmentation Algorithms}},
    volume = {85},
    year = {2009}
}

@inproceedings{Tola2008Fast,
    abstract = {{We introduce a novel local image descriptor designed for dense wide-baseline matching purposes. We feed our descriptors to a graph-cuts based dense depth map estimation algorithm and this yields better wide-baseline performance than the commonly used correlation windows for which the size is hard to tune. As a result, unlike competing techniques that require many high-resolution images to produce good reconstructions, our descriptor can compute them from pairs of low-quality images such as the ones captured by video streams. Our descriptor is inspired from earlier ones such as SIFT and GLOH but can be computed much faster for our purposes. Unlike SURF which can also be computed efficiently at every pixel, it does not introduce artifacts that degrade the matching performance. Our approach was tested with ground truth laser scanned depth maps as well as on a wide variety of image pairs of different resolutions and we show that good reconstructions are achieved even with only two low quality images.}},
    author = {Tola, E. and Lepetit, V. and Fua, P.},
    booktitle = {Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on},
    citeulike-article-id = {3478097},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2008.4587673},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4587673},
    institution = {Comput. Vision Lab., Ecole Polytech. Fed. de Lausanne, Lausanne},
    isbn = {978-1-4244-2242-5},
    issn = {1063-6919},
    journal = {Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on},
    keywords = {photo\_consistency},
    month = jun,
    pages = {1--8},
    posted-at = {2012-03-22 03:22:28},
    priority = {2},
    publisher = {IEEE},
    title = {{A fast local descriptor for dense matching}},
    year = {2008}
}

@inproceedings{Sun2005Image,
    abstract = {{In this paper, we introduce a novel approach to image completion, which we call structure propagation. In our system, the user manually specifies important missing structure information by extending a few curves or line segments from the known to the unknown regions. Our approach synthesizes image patches along these user-specified curves in the unknown region using patches selected around the curves in the known region. Structure propagation is formulated as a global optimization problem by enforcing structure and consistency constraints. If only a single curve is specified, structure propagation is solved using Dynamic Programming. When multiple intersecting curves are specified, we adopt the Belief Propagation algorithm to find the optimal patches. After completing structure propagation, we fill in the remaining unknown regions using patch-based texture synthesis. We show that our approach works well on a number of examples that are challenging to state-of-the-art techniques.}},
    address = {New York, NY, USA},
    author = {Sun, Jian and Yuan, Lu and Jia, Jiaya and Shum, Heung Y.},
    booktitle = {ACM SIGGRAPH 2005 Papers},
    citeulike-article-id = {3912659},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1073274},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1186822.1073274},
    keywords = {belief\_propagation, dynamic\_programming, inpainting},
    location = {Los Angeles, California},
    pages = {861--868},
    posted-at = {2012-03-21 15:45:15},
    priority = {2},
    publisher = {ACM},
    series = {SIGGRAPH '05},
    title = {{Image completion with structure propagation}},
    year = {2005}
}

@article{Szeliski2008Comparative,
    abstract = {{Among the most exciting advances in early vision has been the development of efficient energy minimization algorithms for pixel-labeling tasks such as depth or texture computation. It has been known for decades that such problems can be elegantly expressed as Markov random fields, yet the resulting energy minimization problems have been widely viewed as intractable. Algorithms such as graph cuts and loopy belief propagation (LBP) have proven to be very powerful: For example, such methods form the basis for almost all the top-performing stereo methods. However, the trade-offs among different energy minimization algorithms are still not well understood. In this paper, we describe a set of energy minimization benchmarks and use them to compare the solution quality and runtime of several common energy minimization algorithms. We investigate three promising methods-graph cuts, LBP, and tree-reweighted message passing-in addition to the well-known older iterated conditional mode (ICM) algorithm. Our benchmark problems are drawn from published energy functions used for stereo, image stitching, interactive segmentation, and denoising. We also provide a general-purpose software interface that allows vision researchers to easily switch between optimization methods. The benchmarks, code, images, and results are available at http://vision.middlebury.edu/MRF/.}},
    address = {Los Alamitos, CA, USA},
    author = {Szeliski, R. and Zabih, R. and Scharstein, D. and Veksler, O. and Kolmogorov, V. and Agarwala, A. and Tappen, M. and Rother, C.},
    booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    citeulike-article-id = {3339395},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1399441},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/TPAMI.2007.70844},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/TPAMI.2007.70844},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4420084},
    institution = {Microsoft Res., Redmond, WA},
    issn = {0162-8828},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {energy\_minimization, mrf, survey},
    month = jun,
    number = {6},
    pages = {1068--1080},
    posted-at = {2012-03-21 15:42:06},
    priority = {2},
    publisher = {IEEE},
    title = {{A Comparative Study of Energy Minimization Methods for Markov Random Fields with Smoothness-Based Priors}},
    volume = {30},
    year = {2008}
}

@article{Boykov2006Graph,
    abstract = {{Combinatorial graph cut algorithms have been successfully applied to a wide range of problems in vision and graphics. This paper focusses on possibly the simplest application of graph-cuts: segmentation of objects in image data. Despite its simplicity, this application epitomizes the best features of combinatorial graph cuts methods in vision: global optima, practical efficiency, numerical robustness, ability to fuse a wide range of visual cues and constraints, unrestricted topological properties of segments, and applicability to N-D problems. Graph cuts based approaches to object extraction have also been shown to have interesting connections with earlier segmentation methods such as snakes, geodesic active contours, and level-sets. The segmentation energies optimized by graph cuts combine boundary regularization with region-based properties in the same fashion as Mumford-Shah style functionals. We present motivation and detailed technical description of the basic combinatorial optimization framework for image segmentation via s/t graph cuts. After the general concept of using binary graph cut algorithms for object segmentation was first proposed and tested in Boykov and Jolly (2001), this idea was widely studied in computer vision and graphics communities. We provide links to a large number of known extensions based on iterative parameter re-estimation and learning, multi-scale or hierarchical approaches, narrow bands, and other techniques for demanding photo, video, and medical applications.}},
    address = {Hingham, MA, USA},
    author = {Boykov, Yuri and Lea, Gareth F.},
    citeulike-article-id = {984876},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1147793.1147801},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s11263-006-7934-5},
    citeulike-linkout-2 = {http://www.springerlink.com/content/j3k24j8347k42425},
    day = {1},
    issn = {0920-5691},
    journal = {Int. J. Comput. Vision},
    keywords = {energy\_minimization, graph\_cut, segmentation},
    month = nov,
    number = {2},
    pages = {109--131},
    posted-at = {2012-03-21 15:23:50},
    priority = {4},
    publisher = {Kluwer Academic Publishers},
    title = {{Graph Cuts and Efficient N-D Image Segmentation}},
    volume = {70},
    year = {2006}
}

@inproceedings{Delong2010Fast,
    abstract = {{The α-expansion algorithm has had a significant impact in computer vision due to its generality, effectiveness, and speed. Thus far it can only minimize energies that involve unary, pairwise, and specialized higher-order terms. Our main contribution is to extend α-expansion so that it can simultaneously optimize  ” label costs” as well. An energy with label costs can penalize a solution based on the set of labels that appear in it. The simplest special case is to penalize the number of labels in the solution. Our energy is quite general, and we prove optimality bounds for our algorithm. A natural application of label costs is multi-model fitting, and we demonstrate several such applications in vision: homography detection, motion segmentation, and unsupervised image segmentation. Our C++/MATLAB implementation is publicly available.}},
    author = {Delong, A. and Osokin, A. and Isack, H. N. and Boykov, Y.},
    booktitle = {Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on},
    citeulike-article-id = {10263608},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2010.5539897},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5539897},
    institution = {Dept. of Comput. Sci., Univ. of Western Ontario, London, ON, Canada},
    isbn = {978-1-4244-6984-0},
    issn = {1063-6919},
    keywords = {alpha\_expansion, energy\_minimization},
    month = jun,
    pages = {2173--2180},
    posted-at = {2012-03-19 23:39:42},
    priority = {2},
    publisher = {IEEE},
    title = {{Fast approximate energy minimization with label costs}},
    year = {2010}
}

@article{Boykov2001Fast,
    abstract = {{Many tasks in computer vision involve assigning a label (such as
disparity) to every pixel. A common constraint is that the labels should
vary smoothly almost everywhere while preserving sharp discontinuities
that may exist, e.g., at object boundaries. These tasks are naturally
stated in terms of energy minimization. The authors consider a wide
class of energies with various smoothness constraints. Global
minimization of these energy functions is NP-hard even in the simplest
discontinuity-preserving case. Therefore, our focus is on efficient
approximation algorithms. We present two algorithms based on graph cuts
that efficiently find a local minimum with respect to two types of large
moves, namely expansion moves and swap moves. These moves can
simultaneously change the labels of arbitrarily large sets of pixels. In
contrast, many standard algorithms (including simulated annealing) use
small moves where only one pixel changes its label at a time. Our
expansion algorithm finds a labeling within a known factor of the global
minimum, while our swap algorithm handles more general energy functions.
Both of these algorithms allow important cases of discontinuity
preserving energies. We experimentally demonstrate the effectiveness of
our approach for image restoration, stereo and motion. On real data with
ground truth, we achieve 98 percent accuracy}},
    address = {Los Alamitos, CA, USA},
    author = {Boykov, Y. and Veksler, O. and Zabih, R.},
    citeulike-article-id = {265930},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=505473},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/34.969114},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/34.969114},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=969114},
    institution = {Siemens Corp. Res., Princeton, NJ},
    issn = {0162-8828},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {graph\_cut, mrf},
    month = nov,
    number = {11},
    pages = {1222--1239},
    posted-at = {2012-03-19 23:34:39},
    priority = {5},
    publisher = {IEEE},
    title = {{Fast approximate energy minimization via graph cuts}},
    volume = {23},
    year = {2001}
}

@article{Shotton2009TextonBoost,
    abstract = {{This paper details a new approach for learning a discriminative model of object classes, incorporating texture, layout, and context information efficiently. The learned model is used for automatic visual understanding and semantic segmentation of photographs. Our discriminative model exploits texture-layout filters, novel features based on textons, which jointly model patterns of texture and their spatial layout. Unary classification and feature selection is achieved using shared boosting to give an efficient classifier which can be applied to a large number of classes. Accurate image segmentation is achieved by incorporating the unary classifier in a conditional random field, which (i) captures the spatial interactions between class labels of neighboring pixels, and (ii) improves the segmentation of specific object instances. Efficient training of the model on large datasets is achieved by exploiting both random feature selection and piecewise training methods.  High classification and segmentation accuracy is demonstrated on four varied databases: (i) the MSRC 21-class database containing photographs of real objects viewed under general lighting conditions, poses and viewpoints, (ii) the 7-class Corel subset and (iii) the 7-class Sowerby database used in He et al. (Proceeding of IEEE Conference on Computer Vision and Pattern Recognition, vol. 2, pp. 695---702, June 2004), and (iv) a set of video sequences of television shows. The proposed algorithm gives competitive and visually pleasing results for objects that are highly textured (grass, trees, etc.), highly structured (cars, faces, bicycles, airplanes, etc.), and even articulated (body, cow, etc.).}},
    address = {Hingham, MA, USA},
    author = {Shotton, Jamie and Winn, John and Rother, Carsten and Criminisi, Antonio},
    citeulike-article-id = {3855055},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1487516},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s11263-007-0109-1},
    citeulike-linkout-2 = {http://www.springerlink.com/content/71556x2n0809ql11},
    day = {1},
    issn = {0920-5691},
    journal = {Int. J. Comput. Vision},
    keywords = {mrf, recognition, segmentation},
    month = jan,
    number = {1},
    pages = {2--23},
    posted-at = {2012-03-19 20:10:29},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {{TextonBoost for Image Understanding: Multi-Class Object Recognition and Segmentation by Jointly Modeling Texture, Layout, and Context}},
    volume = {81},
    year = {2009}
}

@inproceedings{Winn2006Layout,
    abstract = {{This paper addresses the problem of detecting and segmenting partially occluded objects of a known category. We first define a part labelling which densely covers the object. Our Layout Consistent Random Field (LayoutCRF) model then imposes asymmetric local spatial constraints on these labels to ensure the consistent layout of parts whilst allowing for object deformation. Arbitrary occlusions of the object are handled by avoiding the assumption that the whole object is visible. The resulting system is both efficient to train and to apply to novel images, due to a novel annealed layout-consistent expansion move algorithm paired with a randomised decision tree classifier. We apply our technique to images of cars and faces and demonstrate state-of-the-art detection and segmentation performance even in the presence of partial occlusion.}},
    author = {Winn, J. and Shotton, J.},
    booktitle = {Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on},
    citeulike-article-id = {1139916},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1153395},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/CVPR.2006.305},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1640739},
    institution = {Microsoft Research Cambridge Cambridge, UK},
    isbn = {0-7695-2597-0},
    issn = {1063-6919},
    journal = {Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on},
    keywords = {mrf, occlusion, recognition, segmentation},
    month = jun,
    pages = {37--44},
    posted-at = {2012-03-19 20:08:20},
    priority = {2},
    publisher = {IEEE},
    title = {{The Layout Consistent Random Field for Recognizing and Segmenting Partially Occluded Objects}},
    volume = {1},
    year = {2006}
}

@inproceedings{Golovinskiy2009Shapebased,
    abstract = {{This paper investigates the design of a system for recognizing objects in 3D point clouds of urban environments. The system is decomposed into four steps: locating, segmenting, characterizing, and classifying clusters of 3D points. Specifically, we first cluster nearby points to form a set of potential object locations (with hierarchical clustering). Then, we segment points near those locations into foreground and background sets (with a graph-cut algorithm). Next, we build a feature vector for each point cluster (based on both its shape and its context). Finally, we label the feature vectors using a classifier trained on a set of manually labeled objects. The paper presents several alternative methods for each step. We quantitatively evaluate the system and tradeoffs of different alternatives in a truthed part of a scan of Ottawa that contains approximately 100 million points and 1000 objects of interest. Then, we use this truth data as a training set to recognize objects amidst approximately 1 billion points of the remainder of the Ottawa scan.}},
    author = {Golovinskiy, A. and Kim, V. G. and Funkhouser, T.},
    booktitle = {Computer Vision, 2009 IEEE 12th International Conference on},
    citeulike-article-id = {10476504},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICCV.2009.5459471},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5459471},
    institution = {Princeton Univ., Princeton, NJ, USA},
    isbn = {978-1-4244-4420-5},
    issn = {1550-5499},
    keywords = {point\_cloud, recognition},
    pages = {2154--2161},
    posted-at = {2012-03-19 15:29:11},
    priority = {2},
    publisher = {IEEE},
    title = {{Shape-based recognition of 3D point clouds in urban environments}},
    year = {2009}
}

@incollection{Hornung2006Robust,
    abstract = {{Estimating photo-consistency is one of the most important ingredients for any 3D stereo reconstruction technique that is based on a volumetric scene representation. This paper presents a new, illumination invariant photo-consistency measure for high quality, volumetric 3D reconstruction from calibrated images. In contrast to current standard methods such as normalized cross-correlation it supports unconstrained camera setups and non-planar surface approximations. We show how this measure can be embedded into a highly efficient, completely hardware accelerated volumetric reconstruction pipeline by exploiting current graphics processors. We provide examples of high quality reconstructions with computation times of only a few seconds to minutes, even for large numbers of cameras and high volumetric resolutions.}},
    address = {Berlin, Heidelberg},
    author = {Hornung, Alexander and Kobbelt, Leif},
    booktitle = {Computer Vision – ECCV 2006 },
    chapter = {14},
    citeulike-article-id = {6939593},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11744047\_14},
    citeulike-linkout-1 = {http://www.springerlink.com/content/v076h7n83374733w},
    editor = {Leonardis, Ale\v{s} and Bischof, Horst and Pinz, Axel},
    isbn = {978-3-540-33834-5},
    keywords = {photo\_consistency},
    pages = {179--190},
    posted-at = {2012-03-19 03:57:21},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{Robust and Efficient Photo-Consistency Estimation for Volumetric 3D Reconstruction Computer Vision – ECCV 2006}},
    volume = {3952},
    year = {2006}
}

@inproceedings{Szeliski1999Prediction,
    abstract = {{This paper presents a new methodology for evaluating the quality
of motion estimation and stereo correspondence algorithms. Motivated by
applications such as novel view generation and motion-compensated
compression, we suggest that the ability to predict new views or frames
is a natural metric for evaluating such algorithms. Our new metric has
several advantages over comparing algorithm outputs to true motions or
depths. First of all, it does not require the knowledge of ground truth
data, which may be difficult or laborious to obtain. Second, it more
closely matches the ultimate requirements of the application, which are
typically tolerant of errors in uniform color regions, but very
sensitive to isolated pixel errors or disocclusion errors. In the paper
we develop a number of error metrics based on this paradigm, including
forward and inverse prediction errors, residual motion error and local
motion-compensated prediction error. We show results on a number of
widely used motion and stereo sequences, many of which do not have
associated ground truth data}},
    author = {Szeliski, R.},
    booktitle = {Computer Vision, 1999. The Proceedings of the Seventh IEEE International Conference on},
    citeulike-article-id = {10475085},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICCV.1999.790301},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=790301},
    institution = {Vision Technol. Group, Microsoft Corp., Redmond, WA},
    isbn = {0-7695-0164-8},
    keywords = {photo\_consistency},
    pages = {781--788 vol.2},
    posted-at = {2012-03-19 03:37:36},
    priority = {5},
    publisher = {IEEE},
    title = {{Prediction error as a quality metric for motion and stereo}},
    volume = {2},
    year = {1999}
}

@inproceedings{Lasseter1987Principles,
    abstract = {{This paper describes the basic principles of traditional 2D hand drawn animation and their application to 3D computer animation. After describing how these principles evolved, the individual principles are detailed, addressing their meanings in 2D hand drawn animation and their application to 3D computer animation. This should demonstrate the importance of these principles to quality 3D computer animation.}},
    address = {New York, NY, USA},
    author = {Lasseter, John},
    booktitle = {Proceedings of the 14th annual conference on Computer graphics and interactive techniques},
    citeulike-article-id = {305234},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=37407},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/37401.37407},
    isbn = {0-89791-227-6},
    keywords = {animation},
    month = jul,
    number = {4},
    pages = {35--44},
    posted-at = {2012-03-14 21:06:52},
    priority = {2},
    publisher = {ACM},
    series = {SIGGRAPH '87},
    title = {{Principles of traditional animation applied to 3D computer animation}},
    volume = {21},
    year = {1987}
}

@article{Edelsbrunner1986Halfplanar,
    abstract = {{Let S denote a set of n points in the Euclidean plane. A halfplanar range query specifies a halfplane h and requires the determination of the number of points in S which are contained in h. A new data structure is described which stores S in O(n) space and allows us to answer a halfplanar range query in O(nlog2(1+√5)−1) time in the worst case, thus improving the best result known before. The structure can be built in O(n log n) time.}},
    author = {Edelsbrunner, Herbert and Welzl, Emo},
    citeulike-article-id = {10426132},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0020-0190(86)90088-8},
    issn = {00200190},
    journal = {Information Processing Letters},
    keywords = {computational\_geometry},
    month = nov,
    number = {5},
    pages = {289--293},
    posted-at = {2012-03-08 02:09:50},
    priority = {2},
    title = {{Halfplanar range search in linear space and O(n0.695) query time}},
    volume = {23},
    year = {1986}
}

@article{Chazelle1989Quasioptimal,
    abstract = {{The range-searching problems that allow efficient partition trees are characterized as those defined by range spaces of finite Vapnik-Chervonenkis dimension. More generally, these problems are shown to be the only ones that admit linear-size solutions with sublinear query time in the arithmetic model. The proof rests on a characterization of spanning trees with a low stabbing number. We use probabilistic arguments to treat the general case, but we are able to use geometric techniques to handle the most common range-searching problems, such as simplex and spherical range search. We prove that any set of n points in E d admits a spanning tree which cannot be cut by any hyperplane (or hypersphere) through more than roughly n 1−1/d edges. This result yields quasi-optimal solutions to simplex range searching in the arithmetic model of computation. We also look at polygon, disk, and tetrahedron range searching on a random access machine. Given n points in E 2 , we derive a data structure of size O ( n log n ) for counting how many points fall inside a query convex k -gon (for arbitrary values of k ). The query time is O (√ kn log n ). If k is fixed once and for all (as in triangular range searching), then the storage requirement drops to O ( n ). We also describe an O ( n log n )-size data structure for counting how many points fall inside a query circle in O (√ n log 2 n ) query time. Finally, we present an O ( n log n )-size data structure for counting how many points fall inside a query tetrahedron in 3-space in O ( n 2/3 log 2 n ) query time. All the algorithms are optimal within polylogarithmic factors. In all cases, the preprocessing can be done in polynomial time. Furthermore, the algorithms can also handle reporting within the same complexity (adding the size of the output as a linear term to the query time).}},
    author = {Chazelle, Bernard and Welzl, Emo},
    citeulike-article-id = {10426128},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/BF02187743},
    citeulike-linkout-1 = {http://www.springerlink.com/content/p6662480642m4553},
    day = {30},
    issn = {0179-5376},
    journal = {Discrete \& Computational Geometry},
    keywords = {computational\_geometry, range\_search, vc\_dimension},
    month = dec,
    number = {1},
    pages = {467--489},
    posted-at = {2012-03-08 02:07:37},
    priority = {2},
    publisher = {Springer New York},
    title = {{Quasi-optimal range searching in spaces of finite VC-dimension}},
    volume = {4},
    year = {1989}
}

@article{Cipra2000Best,
    author = {Cipra, B. A.},
    citeulike-article-id = {6838680},
    journal = {SIAM News},
    keywords = {algorithm, best},
    posted-at = {2012-02-26 00:09:08},
    priority = {2},
    title = {{The Best of the 20th Century: Editors Name Top 10 Algorithms}},
    volume = {33},
    year = {2000}
}

@article{Baker2004LucasKanade,
    abstract = {{Since the Lucas-Kanade algorithm was proposed in 1981 image alignment has become one of the most widely used techniques in computer vision. Applications range from optical flow and tracking to layered motion, mosaic construction, and face coding. Numerous algorithms have been proposed and a wide variety of extensions have been made to the original formulation. We present an overview of image alignment, describing most of the algorithms and their extensions in a consistent framework. We concentrate on the inverse compositional algorithm, an efficient algorithm that we recently proposed. We examine which of the extensions to Lucas-Kanade can be used with the inverse compositional algorithm without any significant loss of efficiency, and which cannot. In this paper, Part 1 in a series of papers, we cover the quantity approximated, the warp update rule, and the gradient descent approximation. In future papers, we will cover the choice of the error function, how to allow linear appearance variation, and how to impose priors on the parameters.}},
    author = {Baker, Simon and Matthews, Iain},
    citeulike-article-id = {1238610},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=964568.964604},
    citeulike-linkout-1 = {http://dx.doi.org/10.1023/B:VISI.0000011205.11775.fd},
    citeulike-linkout-2 = {http://www.springerlink.com/content/t032h4pg050x2012},
    day = {1},
    issn = {0920-5691},
    journal = {International Journal of Computer Vision},
    keywords = {hessian, incremental, jacobian, optical\_flow, stitch},
    month = feb,
    number = {3},
    pages = {221--255},
    posted-at = {2012-02-21 01:15:28},
    priority = {2},
    publisher = {Springer Netherlands},
    title = {{Lucas-Kanade 20 Years On: A Unifying Framework}},
    volume = {56},
    year = {2004}
}

@inproceedings{Taylor2009Robust,
    abstract = {{In this paper we present a robust feature matching scheme in which features can be matched in 2.3 mus. For a typical task involving 150 features per image, this results in a processing time of 500 mus for feature extraction and matching. In order to achieve very fast matching we use simple features based on histograms of pixel intensities and an indexing scheme based on their joint distribution. The features are stored with a novel bit mask representation which requires only 44 bytes of memory per feature and allows computation of a dissimilarity score in 20 ns. A training phase gives the patch-based features invariance to small viewpoint variations. Larger viewpoint variations are handled by training entirely independent sets of features from different viewpoints. A complete system is presented where a database of around 13,000 features is used to robustly localise a single planar target in just over a millisecond, including all steps from feature detection to model fitting. The resulting system shows comparable robustness to SIFT and Ferns while using a tiny fraction of the processing time, and in the latter case a fraction of the memory as well.}},
    author = {Taylor, S. and Rosten, E. and Drummond, T.},
    booktitle = {Computer Vision and Pattern Recognition Workshops, 2009. CVPR Workshops 2009. IEEE Computer Society Conference on},
    citeulike-article-id = {6012690},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2009.5204314},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5204314},
    day = {18},
    institution = {Dept. of Eng., Univ. of Cambridge, Cambridge, UK},
    isbn = {978-1-4244-3994-2},
    journal = {Computer Vision and Pattern Recognition Workshops, 2009. CVPR Workshops 2009. IEEE Computer Society Conference on},
    keywords = {cv, feature, matching, real\_time},
    month = jun,
    pages = {15--22},
    posted-at = {2012-02-19 22:13:47},
    priority = {4},
    publisher = {IEEE},
    title = {{Robust feature matching in 2.3µs}},
    year = {2009}
}

@article{Stuelpnagel1964Parametrization,
    author = {Stuelpnagel, John},
    citeulike-article-id = {10368717},
    citeulike-linkout-0 = {http://www.jstor.org/stable/2027966},
    issn = {00361445},
    journal = {SIAM Review},
    keywords = {group, quaternion, rotation},
    number = {4},
    pages = {422--430},
    posted-at = {2012-02-19 20:59:17},
    priority = {2},
    publisher = {Society for Industrial and Applied Mathematics},
    title = {{On the Parametrization of the Three-Dimensional Rotation Group}},
    volume = {6},
    year = {1964}
}

@article{Guillemaut2011Joint,
    abstract = {{Current state-of-the-art image-based scene reconstruction techniques are capable of generating high-fidelity 3D models when used under controlled capture conditions. However, they are often inadequate when used in more challenging environments such as sports scenes with moving cameras. Algorithms must be able to cope with relatively large calibration and segmentation errors as well as input images separated by a wide-baseline and possibly captured at different resolutions. In this paper, we propose a technique which, under these challenging conditions, is able to efficiently compute a high-quality scene representation via graph-cut optimisation of an energy function combining multiple image cues with strong priors. Robustness is achieved by jointly optimising scene segmentation and multiple view reconstruction in a view-dependent manner with respect to each input camera. Joint optimisation prevents propagation of errors from segmentation to reconstruction as is often the case with sequential approaches. View-dependent processing increases tolerance to errors in through-the-lens calibration compared to global approaches. We evaluate our technique in the case of challenging outdoor sports scenes captured with manually operated broadcast cameras as well as several indoor scenes with natural background. A comprehensive experimental evaluation including qualitative and quantitative results demonstrates the accuracy of the technique for high quality segmentation and reconstruction and its suitability for free-viewpoint video under these difficult conditions.}},
    author = {Guillemaut, Jean-Yves and Hilton, Adrian},
    citeulike-article-id = {8637689},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11263-010-0413-z},
    citeulike-linkout-1 = {http://www.springerlink.com/content/a070542517610153},
    day = {1},
    issn = {0920-5691},
    journal = {International Journal of Computer Vision},
    keywords = {mvs, reconstruction, segmentation, video, view\_interpolation},
    month = may,
    number = {1},
    pages = {73--100},
    posted-at = {2012-02-18 23:00:20},
    priority = {2},
    publisher = {Springer Netherlands},
    title = {{Joint Multi-Layer Segmentation and Reconstruction for Free-Viewpoint Video Applications}},
    volume = {93},
    year = {2011}
}

@inproceedings{Xie2006Building,
    abstract = {{Building information is extremely important for many applications such as urban planning, telecommunication, or environment monitoring etc. Previous attempts at automating the building detection process from images has met with limited success due to (1) spectral similarities between building rooftops and roads, (2) lack of spatial processing parameters for building geometry. A novel approach is presented in this paper based on aerial images and range images. By using the height information provided by range images, buildings could be easily distinguish from other objects (e.g. roads). A new perceptual grouping technique is introduced for the purpose of organizing the low-level features (arcs and line segments) which are extracted from aerial images. The final contours of the buildings are generated with the help of regularization algorithm. After reconstruction, a refinement is applied by an object-based perceptual grouping method. Finally, the approach is applied to two datasets and promising experimental results are shown}},
    author = {Xie, Minghong and Fu, Kun and Wu, Yirong},
    booktitle = {Radar, 2006. CIE '06. International Conference on},
    citeulike-article-id = {10363627},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICR.2006.343296},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4148402},
    institution = {lnst. of Electron., Chinese Acad. of Sci., Beijing},
    isbn = {0-7803-9582-4},
    keywords = {aerial, building, city, fusion, image, lidar, recognition, reconstruction},
    month = oct,
    pages = {1--4},
    posted-at = {2012-02-18 08:35:52},
    priority = {2},
    publisher = {IEEE},
    title = {{Building Recognition and Reconstruction from Aerial Imagery and LIDAR Data}},
    year = {2006}
}

@inproceedings{Poullis2009Automatic,
    abstract = {{In this paper, we address the complex problem of rapid modeling of large-scale areas and present a novel approach for the automatic reconstruction of cities from remote sensor data. The goal in this work is to automatically create lightweight, watertight polygonal 3D models from LiDAR data (Light Detection and Ranging) captured by an airborne scanner. This is achieved in three steps: preprocessing, segmentation and modeling, as shown in Figure 1. Our main technical contributions in this paper are: (i) a novel, robust, automatic segmentation technique based on the statistical analysis of the geometric properties of the data, which makes no particular assumptions about the input data, thus having no data dependencies, and (ii) an efficient and automatic modeling pipeline for the reconstruction of large-scale areas containing several thousands of buildings. We have extensively tested the proposed approach with several city-size datasets including downtown Baltimore, downtown Denver, the city of Atlanta, downtown Oakland, and we present and evaluate the experimental results.}},
    author = {Poullis, C. and You, S.},
    booktitle = {Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
    citeulike-article-id = {5815159},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPRW.2009.5206562},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5206562},
    day = {18},
    institution = {CGIT/IMSC, Univ. of Southern California, Los Angeles, CA, USA},
    isbn = {978-1-4244-3992-8},
    issn = {1063-6919},
    journal = {Computer Vision and Pattern Recognition Workshops, 2009. CVPR Workshops 2009. IEEE Computer Society Conference on},
    keywords = {aerial, building, city, lidar, reconstruction, segmentation},
    month = jun,
    pages = {2775--2782},
    posted-at = {2012-02-18 08:34:17},
    priority = {2},
    publisher = {IEEE},
    title = {{Automatic reconstruction of cities from remote sensor data}},
    year = {2009}
}

@inproceedings{Kim2009Multiview,
    abstract = {{Multi-view stereo methods frequently fail to properly reconstruct 3D scene geometry if visible texture is sparse or the scene exhibits difficult self-occlusions. Time-of-Flight (ToF) depth sensors can provide 3D information regardless of texture but with only limited resolution and accuracy. To find an optimal reconstruction, we propose an integrated multi-view sensor fusion approach that combines information from multiple color cameras and multiple ToF depth sensors. First, multi-view ToF sensor measurements are combined to obtain a coarse but complete model. Then, the initial model is refined by means of a probabilistic multi-view fusion framework, optimizing over an energy function that aggregates ToF depth sensor information with multi-view stereo and silhouette constraints. We obtain high quality dense and detailed 3D models of scenes challenging for stereo alone, while simultaneously reducing complex noise of ToF sensors.}},
    author = {Kim, Young M. and Theobalt, C. and Diebel, J. and Kosecka, J. and Miscusik, B. and Thrun, S.},
    booktitle = {Computer Vision Workshops (ICCV Workshops), 2009 IEEE 12th International Conference on},
    citeulike-article-id = {8502759},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICCVW.2009.5457430},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5457430},
    comment = {(private-note)Instead of using lidar, they fused the multi-view reconstructions of ToF sensor, which is a depth camera, and cameras using a probability model, which balance the advantages of each sensor. },
    institution = {Stanford Univ., Stanford, CA, USA},
    isbn = {978-1-4244-4442-7},
    keywords = {dense, fusion, indoor, mvs, reconstruction, tof},
    location = {Kyoto, Japan},
    month = sep,
    pages = {1542--1549},
    posted-at = {2012-02-18 08:32:54},
    priority = {3},
    publisher = {IEEE},
    title = {{Multi-view image and ToF sensor fusion for dense 3D reconstruction}},
    year = {2009}
}

@inproceedings{Huber20003D,
    abstract = {{We present techniques for building models of complex environments
from range data gathered at multiple viewpoints. The challenges in this
problem are: the matching of unregistered views without prior knowledge
of pose, the use of very large data sets, and the manipulation of data
sets of different resolutions and from different sensors. Our approach
is unique in that no prior knowledge of the relative viewpoints is
needed in order to register the data. We show results in building maps
of interior environment from range finding data, building large terrain
maps from ground-based and from aerial data, and from an operational for
mapping from stereo data for hazardous environment characterization. The
paper summarizes the major results obtained so far in this area}},
    author = {Huber, D. and Carmichael, O. and Hebert, M.},
    booktitle = {Robotics and Automation, 2000. Proceedings. ICRA '00. IEEE International Conference on},
    citeulike-article-id = {10363601},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ROBOT.2000.844162},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=844162},
    institution = {Robotics Inst., Carnegie Mellon Univ., Pittsburgh, PA},
    isbn = {0-7803-5886-4},
    keywords = {aerial, building, city, lidar, reconstruction, registration},
    pages = {891--897 vol.1},
    posted-at = {2012-02-18 08:26:53},
    priority = {2},
    publisher = {IEEE},
    title = {{3D map reconstruction from range data}},
    volume = {1},
    year = {2000}
}

@inproceedings{Carlberg2009Classifying,
    abstract = {{The classification of urban landscape in aerial lidar point clouds is useful in 3D modeling and object recognition applications in urban environments. In this paper, we introduce a multi-category classification system for identifying water, ground, roof, and trees in airborne lidar. The system is organized as a cascade of binary classifiers, each of which performs unsupervised region growing followed by supervised, segment-wise classification. Categories with the most discriminating features, such as water and ground, are identified first and are used as context for identifying more complex categories, such as trees. We use 3D shape analysis and region growing to identify \^{A}¿planar\^{A}¿ and \^{A}¿scatter\^{A}¿ regions that likely correspond to ground/roof and trees respectively. We demonstrate results on two urban datasets, the larger of which contains 200 million lidar returns over 7km}},
    author = {Carlberg, M. and Gao, P. and Chen, G. and Zakhor, A.},
    booktitle = {Image Processing (ICIP), 2009 16th IEEE International Conference on},
    citeulike-article-id = {10363597},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICIP.2009.5413385},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5413385},
    institution = {EECS Dept., Univ. of California, Berkeley, CA, USA},
    isbn = {978-1-4244-5653-6},
    issn = {1522-4880},
    keywords = {aerial, city, classification, lidar, recognition},
    month = nov,
    pages = {1701--1704},
    posted-at = {2012-02-18 08:23:57},
    priority = {2},
    publisher = {IEEE},
    title = {{Classifying urban landscape in aerial LiDAR using 3D shape analysis}},
    year = {2009}
}

@inproceedings{Ding2008Automatic,
    abstract = {{A fast 3D model reconstruction methodology is desirable in many applications such as urban planning, training, and simulations. In this paper, we develop an automated algorithm for texture mapping oblique aerial images onto a 3D model generated from airborne light detection and ranging (LiDAR) data. Our proposed system consists of two steps. In the first step, we combine vanishing points and global positioning system aided inertial system readings to roughly estimate the extrinsic parameters of a calibrated camera. In the second step, we refine the coarse estimate of the first step by applying a series of processing steps. Specifically, We extract 2D corners corresponding to orthogonal 3D structural corners as features from both images and the untextured 3D LiDAR model. The correspondence between an image and the 3D model is then performed using Hough transform and generalized M-estimator sample consensus. The resulting 2D corner matches are used in Lowepsilas algorithm to refine camera parameters obtained earlier. Our system achieves 91\% correct pose recovery rate for 90 images over the downtown Berkeley area, and overall 61\% accuracy rate for 358 images over the residential, downtown and campus portions of the city of Berkeley.}},
    author = {Ding, Min and Lyngbaek, K. and Zakhor, A.},
    booktitle = {Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on},
    citeulike-article-id = {10363593},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2008.4587661},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4587661},
    institution = {Berkeley Electr. Eng. \& Comput. Sci. Dept., Univ. of California, Berkeley, CA},
    isbn = {978-1-4244-2242-5},
    issn = {1063-6919},
    keywords = {aerial, city, lidar, registration},
    month = jun,
    pages = {1--8},
    posted-at = {2012-02-18 08:21:09},
    priority = {2},
    publisher = {IEEE},
    title = {{Automatic registration of aerial imagery with untextured 3D LiDAR models}},
    year = {2008}
}

@inproceedings{Hu2006Integrating,
    abstract = {{This paper presents a hybrid modeling system that fuses LiDAR data, an aerial image and ground view images for rapid creation of accurate building models. Outlines for complex building shapes are interactively extracted from a high-resolution aerial image, surface information is automatically fit with a primitive based method from LiDAR data, and high-resolution ground view images are integrated into the model to generate fully textured CAD models. Our method benefits from the merit of each dataset, and evaluation results are presented on a university campus-size model.}},
    author = {Hu, Jinhui and You, Suya and Neumann, U.},
    booktitle = {3D Data Processing, Visualization, and Transmission, Third International Symposium on},
    citeulike-article-id = {10363590},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/3DPVT.2006.82},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4155726},
    institution = {Univ. of Southern California, Los Angeles, CA},
    isbn = {0-7695-2825-2},
    keywords = {aerial, building, city, fusion, image, lidar, street},
    month = jun,
    pages = {184--191},
    posted-at = {2012-02-18 08:16:27},
    priority = {2},
    publisher = {IEEE},
    title = {{Integrating LiDAR, Aerial Image and Ground Images for Complete Urban Building Modeling}},
    year = {2006}
}

@inproceedings{Zeng2008Simple,
    abstract = {{This paper presents a method for simple regular building reconstruction from LIDAR point cloud. At First, TIN model of the extracted building point from discrete LIDAR point cloud is built. Those points in triangle facet which having the similar normal vector value are clustered into the same plane point set. Then, every plane point set is fitted into plane using the least square method which boundary is decided by convex hull theory. The boundary of building top plane can be optimized based on regular building principle. From the optimized building top boundary and the height of ground, we can calculate the 3D coordinate of every corner point on building. The building model can be constructed based on 3D coordinates of these corner points. The experimental result shows that this method is able to construct effectively simple regular building.}},
    author = {Zeng, Qihong and Lai, Jiazhen and Li, Xianhua and Mao, Jianhua and Liu, Xuefeng},
    booktitle = {Audio, Language and Image Processing, 2008. ICALIP 2008. International Conference on},
    citeulike-article-id = {10363581},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICALIP.2008.4590062},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4590062},
    institution = {Sch. of Commun. \& Inf. Eng., Shanghai Univ., Shanghai},
    isbn = {978-1-4244-1723-0},
    keywords = {building, city, lidar, reconstruction, street},
    month = jul,
    pages = {1040--1044},
    posted-at = {2012-02-18 08:14:54},
    priority = {2},
    publisher = {IEEE},
    title = {{Simple building reconstruction from LIDAR point cloud}},
    year = {2008}
}

@article{Zhang20053D,
    abstract = {{Three-dimensional (3D) reconstruction and texture mapping of buildings or other man-made objects are key aspects for 3D city landscapes. An effective coarse-to-fine approach for 3D building model generation and texture mapping based on digital photogrammetric techniques is proposed. Three video image sequences, two oblique views of building walls and one vertical view of building roofs, acquired by a digital video camera mounted on a helicopter, are used as input images. Lidar data and a coarse two-dimensional (2D) digital vector map used for car navigation are also used as information sources. Automatic aerial triangulation (AAT) suitable for a high overlap image sequence is used to give initial values of camera parameters of each image. To obtain accurate image lines, the correspondence between outlines of the building and their line features in the image sequences is determined with a coarse-to-fine strategy. A hybrid point/line bundle adjustment is used to ensure the stability and accuracy of reconstruction. Reconstructed buildings with fine textures superimposed on a digital elevation model (DEM) and ortho-image are realistically visualised. Experimental results show that the proposed approach of 3D city model generation has a promising future in many applications. La reconstitution tri-dimensionnelle (3D) et la figuration de la texture des b\^{a}timents ou d'autres constructions humaines sont les \'{e}l\'{e}ments cl\'{e}s des paysages urbains 3D. On propose de traiter la r\'{e}alisation de mod\`{e}les 3D des b\^{a}timents int\'{e}grant la texture, par des techniques de photogramm\'{e}trie num\'{e}rique, par une d\'{e}marche efficace allant de l'approch\'{e} au tr\`{e}s fin. Pour cela on a utilis\'{e} en entr\'{e}e trois s\'{e}quences d'images saisies en h\'{e}licopt\`{e}re avec une cam\'{e}ra num\'{e}rique vid\'{e}o, comprenant deux vues obliques des murs des b\^{a}timents et une vue verticale de leurs toits. On a \'{e}galement utilis\'{e} comme source d'informations des donn\'{e}es lidar et une cartographie approch\'{e}e 2D num\'{e}rique en format vecteur servant \`{a} la navigation automobile. Pour obtenir des valeurs initiales sur les param\`{e}tres de la cam\'{e}ra \`{a} chaque image, on a effectu\'{e} une a\'{e}rotriangulation automatique (AAT) sp\'{e}cialement adapt\'{e}e \`{a} une s\'{e}quence d'images \`{a} fort recouvrement. Pour extraire avec pr\'{e}cision tous les segments des images, on utilise une strat\'{e}gie allant de l'approch\'{e} au fin qui permet d'\'{e}tablir les correspondances entre les silhouettes des b\^{a}timents et les d\'{e}tails lin\'{e}aires qui leur appartiennent, tout au long des s\'{e}quences d'images. On s'assure de la stabilit\'{e} et de la pr\'{e}cision de la reconstitution en se servant d'une compensation hybride par faisceaux, m\^{e}lant points et segments. On visualise une reconstitution r\'{e}aliste des b\^{a}timents avec superposition de toute la finesse de leur texture, sous forme de mod\`{e}les num\'{e}riques des \'{e}l\'{e}vations (DEM) et d'ortho-images. Les r\'{e}sultats des essais effectu\'{e}s ont montr\'{e} que la solution propos\'{e}e pour la r\'{e}alisation des mod\`{e}les urbains 3D avait un avenir prometteur pour de nombreuses applications. Zentrale Bestandteile von dreidimensionalen Stadtlandschaften sind die dreidimensionale geometrische Rekonstruktion von Geb\"{a}uden und anderen k\"{u}nstlichen Objekten, und eine realit\"{a}tsnahe Texturierung der Oberfl\"{a}chen. In diesem Beitrag wird ein effektiver Ansatz zur Generierung von 3D-Geb\"{a}udemodellen mit einer Texturierung auf der Basis von Techniken der Digitalen Photogrammetrie vorgestellt. Als Eingabedaten stehen drei Bildsequenzen aus einer digitalen Videokamera zur Verf\"{u}gung, die in einem Helikopter montiert ist. Damit stehen zwei geneigte Ansichten von vertikalen W\"{a}nden von Geb\"{a}uden und eine Senkrechtaufnahme der Dachfl\"{a}chen zur Auswertung zur Verf\"{u}gung. Als weitere Informationsquellen dienen Lidardaten und eine stark generalisierte zweidimensionale digitale Vektorkarte aus der Fahrzeugnavigation. Eine automatische Aerotriangulation (AAT), die f\"{u}r die Bearbeitung von stark \"{u}berlappenden Bildsequenzen geeignet ist, wird zur Bestimmung der gen\"{a}herten Kameraparameter eines jeden Bildes eingesetzt. Um genaue Linien in den Bildern zu erhalten, wird der Bezug zwischen den Umrissen eines Geb\"{a}udes und den zugeh\"{o}rigen Linien in den Bildsequenzen in einer Strategie von grob nach fein ermittelt. Die Stabilit\"{a}t und Genauigkeit der Rekonstruktion st\"{u}tzt sich auf eine hybride B\"{u}ndelausgleichung auf der Basis von Punkten und Linien. Die rekonstruierten Geb\"{a}ude werden mit einer hochaufl\"{o}senden Textur versehen und zusammen mit einem Digitalen H\"{o}henmodell (DEM) und einem Orthobild realit\"{a}tsnah visualisiert. Experimentelle Ergebnisse zeigen, dass dieser Ansatz zur Generierung von 3D-Stadtmodellen eine vielversprechende Zukunft in vielen Anwendungen haben wird. La reconstrucci\'{o}n tridimensional (3D) y la texturizaci\'{o}n de edificios y de otros elementos construidos son procesos fundamentales en la visualizaci\'{o}n 3D de los paisajes urbanos. Se propone un procedimiento ''grosero-a-fino'' para generar un modelo tridimensional texturizado basado en t\'{e}cnicas de fotogrametr\'{\i}a digital. Como informaci\'{o}n de entrada se utilizan tres secuencias de im\'{a}genes de v\'{\i}deo, de las cuales dos son las perspectivas oblicuas de las paredes de los edificios y una la perspectiva vertical de los tejados de los edificios, obtenidas con una c\'{a}mara digital de v\'{\i}deo montada en un helic\'{o}ptero. Tambi\'{e}n se utilizan datos l\'{\i}dar y un mapa vectorial digital plano de los usados en los sistemas de navegaci\'{o}n de veh\'{\i}culos. Para obtener los valores iniciales de los par\'{a}metros de la c\'{a}mara de cada imagen se realiza una triangulaci\'{o}n a\'{e}rea autom\'{a}tica, adecuada para secuencias de im\'{a}genes con mucho solape. A continuaci\'{o}n, y para obtener l\'{\i}neas exactas, se determina la correspondencia entre los contornos de los edificios y los elementos lineales de las im\'{a}genes mediante una estrategia''grosero-a-fino''. Para asegurar la estabilidad y exactitud de la reconstrucci\'{o}n se usa un ajuste por haces h\'{\i}brido punto/l\'{\i}nea. Los edificios as\'{\i} reconstruidos se visualizan con realismo superponiendo texturas finas a un modelo digital de elevaciones (MDE) y a una ortofoto. Los resultados experimentales muestran que el enfoque propuesto para la generaci\'{o}n de un modelo urbano tridimensional tiene un futuro prometedor en muchas aplicaciones.}},
    author = {Zhang, Yongjun and Zhang, Zuxun and Zhang, Jianqing and Wu, Jun},
    citeulike-article-id = {324166},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1477-9730.2005.00316.x},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/bpl/phor/2005/00000020/00000111/art00007},
    issn = {0031-868X},
    journal = {The Photogrammetric Record},
    keywords = {aerial, building, city, fusion, image, lidar},
    month = sep,
    number = {111},
    pages = {285--302},
    posted-at = {2012-02-18 08:13:16},
    priority = {2},
    publisher = {Blackwell Publishing Ltd},
    title = {{3D Building Modelling with Digital Map, Lidar Data and Video Image Sequences}},
    volume = {20},
    year = {2005}
}

@inproceedings{Huber2003Fusion,
    abstract = {{An approach for building reconstruction based on fused information extracted from different data sources, namely LIDAR data (light detection and ranging) and aerial imagery, is proposed. The building reconstruction is performed within the scope of a general surface estimation process. This surface estimation aims at generating a DTM including buildings and vegetation removed. The buildings are reconstructed by applying polyhedral models. Thus a large variety of building types can be described with the only limitation, that the roof surface consists of planes.}},
    author = {Huber, M. and Schickler, W. and Hinz, S. and Baumgartner, A.},
    booktitle = {Remote Sensing and Data Fusion over Urban Areas, 2003. 2nd GRSS/ISPRS Joint Workshop on},
    citeulike-article-id = {8012770},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/DFUA.2003.1219962},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1219962},
    isbn = {0-7803-7719-2},
    keywords = {aerial, building, city, fusion, image, lidar, reconstruction},
    location = {Berlin, Germany},
    month = may,
    pages = {82--86},
    posted-at = {2012-02-18 08:06:56},
    priority = {2},
    publisher = {IEEE},
    title = {{Fusion of LIDAR data and aerial imagery for automatic reconstruction of building surfaces}},
    year = {2003}
}

@article{Xiao2009Imagebased,
    abstract = {{We propose an automatic approach to generate street-side 3D photo-realistic models from images captured along the streets at ground level. We first develop a multi-view semantic segmentation method that recognizes and segments each image at pixel level into semantically meaningful areas, each labeled with a specific object class, such as building, sky, ground, vegetation and car. A partition scheme is then introduced to separate buildings into independent blocks using the major line structures of the scene. Finally, for each block, we propose an inverse patch-based orthographic composition and structure analysis method for fa\c{c}ade modeling that efficiently regularizes the noisy and missing reconstructed 3D data. Our system has the distinct advantage of producing visually compelling results by imposing strong priors of building regularity. We demonstrate the fully automatic system on a typical city example to validate our methodology.}},
    address = {New York, NY, USA},
    author = {Xiao, Jianxiong and Fang, Tian and Zhao, Peng and Lhuillier, Maxime and Quan, Long},
    citeulike-article-id = {7200046},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1618452.1618460},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1618452.1618460},
    issn = {0730-0301},
    journal = {ACM Trans. Graph.},
    keywords = {city, recognition, reconstruction, street},
    month = dec,
    number = {5},
    pages = {1--12},
    posted-at = {2012-02-18 07:53:01},
    priority = {2},
    publisher = {ACM},
    title = {{Image-based street-side city modeling}},
    volume = {28},
    year = {2009}
}

@article{Zhu2011Photorealistic,
    abstract = {{Nowadays, advanced real-time visualization for location-based applications, such as vehicle navigation or mobile phone navigation, requires large scale 3D reconstruction of street scenes. This paper presents methods for generating photorealistic 3D city models from raw mobile laser scanning data, which only contain georeferenced XYZ coordinates of points, to enable the use of photorealistic models in a mobile phone for personal navigation. The main focus is on the automated processing algorithms for noise point filtering, ground and building point classification, detection of planar surfaces, and on the key points (e.g., corners) of building derivation. The test site is located in the Tapiola area, Espoo, Finland. It is an area of commercial buildings, including shopping centers, banks, government agencies, bookstores, and high-rise residential buildings, with the tallest building being 45 m in height. Buildings were extracted by comparing the overlaps of X and Y coordinates of the point clouds between the cutoff-boxes at different and transforming the top-view of the point clouds of each overlap into a binary image and applying standard image processing technology to remove the non-building points, and finally transforming this image back into point clouds. The purpose for using points from cutoff-boxes instead of all points for building detection is to reduce the influence of tree points close to the building facades on building extraction. This method can also be extended to transform point clouds in different views into binary images for various other object extractions. In order to ensure the building geometry completeness, manual check and correction are needed after the key points of building derivation by automated algorithms. As our goal is to obtain photorealistic 3D models for walk-through views, terrestrial images were captured and used for texturing building facades. Currently, fully automatic generation of high quality 3D models is still challenging due to occlusions in both the laser and image data and due to significant illumination changes between the images. Especially when the scene contains both trees and vehicles, fully automated methods cannot achieve satisfactory visual appearance. In our approach, we employed the existing software for texture preparation and mapping.}},
    author = {Zhu, Lingli and Hyypp\"{a}, Juha and Kukko, Antero and Kaartinen, Harri and Chen, Ruizhi},
    citeulike-article-id = {10363514},
    citeulike-linkout-0 = {http://dx.doi.org/10.3390/rs3071406},
    citeulike-linkout-1 = {http://www.mdpi.com/2072-4292/3/7/1406},
    citeulike-linkout-2 = {http://www.mdpi.com/2072-4292/3/7/1406/pdf},
    day = {06},
    journal = {Remote Sensing},
    keywords = {building, city, laser, lidar, manual, photorealistic},
    month = jul,
    number = {7},
    pages = {1406--1426},
    posted-at = {2012-02-18 07:50:43},
    priority = {2},
    title = {{Photorealistic Building Reconstruction from Mobile Laser Scanning Data}},
    volume = {3},
    year = {2011}
}

@inproceedings{Furukawa2009Manhattanworld,
    abstract = {{Multi-view stereo (MVS) algorithms now produce reconstructions that rival laser range scanner accuracy. However, stereo algorithms require textured surfaces, and therefore work poorly for many architectural scenes (e.g., building interiors with textureless, painted walls). This paper presents a novel MVS approach to overcome these limitations for Manhattan World scenes, i.e., scenes that consists of piece-wise planar surfaces with dominant directions. Given a set of calibrated photographs, we first reconstruct textured regions using an existing MVS algorithm, then extract dominant plane directions, generate plane hypotheses, and recover per-view depth maps using Markov random fields. We have tested our algorithm on several datasets ranging from office interiors to outdoor buildings, and demonstrate results that outperform the current state of the art for such texture-poor scenes.}},
    author = {Furukawa, Y. and Curless, B. and Seitz, S. M. and Szeliski, R.},
    booktitle = {Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
    citeulike-article-id = {10363499},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2009.5206867},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5206867},
    institution = {Dept. of Comput. Sci. \& Eng., Univ. of Washington, Seattle, WA, USA},
    isbn = {978-1-4244-3992-8},
    issn = {1063-6919},
    keywords = {city, mvs, street},
    month = jun,
    pages = {1422--1429},
    posted-at = {2012-02-18 07:43:06},
    priority = {2},
    publisher = {IEEE},
    title = {{Manhattan-world stereo}},
    year = {2009}
}

@inproceedings{Leibe2007Dynamic,
    abstract = {{In this paper, we present a system that integrates fully automatic scene geometry estimation, 2D object detection, 3D localization, trajectory estimation, and tracking for dynamic scene interpretation from a moving vehicle. Our sole input are two video streams from a calibrated stereo rig on top of a car. From these streams, we estimate structure-from-motion (SfM) and scene geometry in real-time. In parallel, we perform multi-view/multi-category object recognition to detect cars and pedestrians in both camera images. Using the SfM self-localization, 2D object detections are converted to 3D observations, which are accumulated in a world coordinate frame. A subsequent tracking module analyzes the resulting 3D observations to find physically plausible spacetime trajectories. Finally, a global optimization criterion takes object-object interactions into account to arrive at accurate 3D localization and trajectory estimates for both cars and pedestrians. We demonstrate the performance of our integrated system on challenging real-world data showing car passages through crowded city areas.}},
    author = {Leibe, B. and Cornelis, N. and Cornelis, K. and Van Gool, L.},
    booktitle = {Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on},
    citeulike-article-id = {2587698},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2007.383146},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4270171},
    institution = {ETH Zurich, Zurich},
    isbn = {1-4244-1180-7},
    journal = {Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on},
    keywords = {city, reconstruction, sfm, street},
    month = jun,
    pages = {1--8},
    posted-at = {2012-02-18 07:41:30},
    priority = {2},
    publisher = {IEEE},
    title = {{Dynamic 3D Scene Analysis from a Moving Vehicle}},
    year = {2007}
}

@article{Awrangjeb2010Automatic,
    abstract = {{This paper presents an automatic building detection technique using LIDAR data and multispectral imagery. Two masks are obtained from the LIDAR data: a 'primary building mask' and a 'secondary building mask'. The primary building mask indicates the void areas where the laser does not reach below a certain height threshold. The secondary building mask indicates the filled areas, from where the laser reflects, above the same threshold. Line segments are extracted from around the void areas in the primary building mask. Line segments around trees are removed using the normalized difference vegetation index derived from the orthorectified multispectral images. The initial building positions are obtained based on the remaining line segments. The complete buildings are detected from their initial positions using the two masks and multispectral images in the YIQ colour system. It is experimentally shown that the proposed technique can successfully detect urban residential buildings, when assessed in terms of 15 indices including completeness, correctness and quality.}},
    author = {Awrangjeb, Mohammad and Ravanbakhsh, Mehdi and Fraser, Clive S.},
    citeulike-article-id = {7412211},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.isprsjprs.2010.06.001},
    day = {01},
    issn = {09242716},
    journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
    keywords = {aerial, building, city, image, lidar, line\_segment, multispectral},
    month = sep,
    number = {5},
    pages = {457--467},
    posted-at = {2012-02-18 07:21:40},
    priority = {2},
    title = {{Automatic detection of residential buildings using LIDAR data and multispectral imagery}},
    volume = {65},
    year = {2010}
}

@article{Sohn2007Data,
    abstract = {{This paper aims to present a new approach for automatic extraction of building footprints in a combination of the IKONOS imagery with pan-sharpened multi-spectral bands and the low-sampled (∼ 0.1 points/m2) airborne laser scanning data acquired from the Optech's 1020 ALTM (Airborne Laser Terrain Mapper). Initially, a laser point cluster in 3D object space was recognized as an isolated building object if all the member points were similarly attributed as building points by investigating the height property of laser points and the normalized difference vegetation indices (NDVI) driven from IKONOS imagery. As modelling cues, rectilinear lines around building outlines collected by either data-driven or model-driven manner were integrated in order to compensate the weakness of both methods. Finally, a full description of building outlines was accomplished by merging convex polygons, which were obtained as a building region was hierarchically divided by the extracted lines using the Binary Space Partitioning (BSP) tree. The system performance was evaluated by objective evaluation metrics in comparison to the Ordnance Survey's MasterMap®. This evaluation showed the delineation performance of up to 0.11 (the branching factor) and the detection percentage of 90.1\% (the correctness) and the overall quality of 80.5\%.}},
    author = {Sohn, Gunho and Dowman, Ian},
    citeulike-article-id = {5779686},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.isprsjprs.2007.01.001},
    issn = {09242716},
    journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
    keywords = {aerial, binary\_space\_partitioning, city, fusion, image, lidar},
    month = may,
    number = {1},
    pages = {43--63},
    posted-at = {2012-02-18 07:18:48},
    priority = {2},
    title = {{Data fusion of high-resolution satellite imagery and LiDAR data for automatic building extraction}},
    volume = {62},
    year = {2007}
}

@inproceedings{Mao2009Building,
    abstract = {{It is well know that geometric filters for points cloud can only go so far when removing above-ground phenomena for it's difficult to determine whether a laser point has hit a special object when only spatial analysis is included. And comparing to the discrete points cloud, the high quality, large-coverage images provided by aerial cameras is a very important advantage of photogrammetry, which can be a very important complement data source to the points cloud. And by a process of spectral imagery LIDAR composite, points cloud can be fused with accurate spectral images provided by aerial CCD cameras on the same board. And the points cloud, with both high quality of reflection and geometric properties, can be filtered by integrating the reflectivity and geometric method. In this paper, the measurement characteristics and advantages of reflectivity of laser scanning and CCD cameras for the classification of return points are analyzed, and a building extraction method, integrating the geometric feature and reflectivity information of the return's intensity and the spectral range of CCD camera are presented. In which, the vegetation points are filtered by spectral attributes initially, and then points belonged to the building walls are segmented by a area attributes after constructing the return points' voronoi diagram; and building surface points are filtered by plane-fitting clustering method.}},
    author = {Mao, Jianhua and Liu, Xuefeng and Zeng, Qihong},
    booktitle = {Urban Remote Sensing Event, 2009 Joint},
    citeulike-article-id = {10363470},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/URS.2009.5137631},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5137631},
    institution = {Res. Centre of Remote Sensing \& Spatial Inf. Sci., Shanghai Univ., Shanghai, China},
    isbn = {978-1-4244-3460-2},
    keywords = {aerial, building, city, fusion, image, lidar},
    month = may,
    pages = {1--5},
    posted-at = {2012-02-18 07:16:30},
    priority = {2},
    publisher = {IEEE},
    title = {{Building extraction by fusion of LIDAR data and aerial images}},
    year = {2009}
}

@incollection{Nicklin2007Rolling,
    abstract = {{This paper describes corrections to image distortion found on the Sony AIBO ERS-7 robots. When obtaining an image the camera captures each pixel in series, that is there is effectively a 'rolling shutter'. This results in a delay between the capture of the first and last pixel. When combined with movement of the camera the image produced will be distorted. The sensor values from the robot, coupled with knowledge of the camera's timing, are used to calculate the effect of the robots movement on the image. This information can then be used to remove much of the distortion from the image. The correction improves the effectiveness of shape recognition and bearing-to-object accuracy.}},
    address = {Berlin, Heidelberg},
    author = {Nicklin, Steven P. and Fisher, Robin D. and Middleton, Richard H.},
    booktitle = {RoboCup 2006: Robot Soccer World Cup X},
    chapter = {39},
    citeulike-article-id = {10360904},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-74024-7\_39},
    citeulike-linkout-1 = {http://www.springerlink.com/content/r51t325gl07qt1pp},
    editor = {Lakemeyer, Gerhard and Sklar, Elizabeth and Sorrenti, Domenico G. and Takahashi, Tomoichi},
    isbn = {978-3-540-74023-0},
    issn = {0302-9743},
    keywords = {compensation, rolling\_shutter},
    pages = {402--409},
    posted-at = {2012-02-17 05:49:12},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{Rolling Shutter Image Compensation RoboCup 2006: Robot Soccer World Cup X}},
    volume = {4434},
    year = {2007}
}

@inproceedings{Klein2009Parallel,
    abstract = {{Camera phones are a promising platform for hand-held augmented reality. As their computational resources grow, they are becoming increasingly suitable for visual tracking tasks. At the same time, they still offer considerable challenges: Their cameras offer a narrow field-of-view not best suitable for robust tracking; images are often received at less than 15 Hz; long exposure times result in significant motion blur; and finally, a rolling shutter causes severe smearing effects. This paper describes an attempt to implement a keyframe-based SLAMsystem on a camera phone (specifically, the Apple iPhone 3 G). We describe a series of adaptations to the Parallel Tracking and Mapping system to mitigate the impact of the device's imaging deficiencies. Early results demonstrate a system capable of generating and augmenting small maps, albeit with reduced accuracy and robustness compared to SLAM on a PC.}},
    address = {Washington, DC, USA},
    author = {Klein, G. and Murray, D.},
    booktitle = {Mixed and Augmented Reality, 2009. ISMAR 2009. 8th IEEE International Symposium on},
    citeulike-article-id = {7227038},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1681509.1682369},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ISMAR.2009.5336495},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5336495},
    institution = {Dept. of Eng. Sci., Univ. of Oxford, Oxford, UK},
    isbn = {978-1-4244-5390-0},
    keywords = {ar, mobile, rolling\_shutter, slam},
    location = {Orlando, FL, USA},
    month = oct,
    pages = {83--86},
    posted-at = {2012-02-16 23:25:33},
    priority = {2},
    publisher = {IEEE},
    title = {{Parallel Tracking and Mapping on a camera phone}},
    year = {2009}
}

@incollection{Triggs2000Bundle,
    abstract = {{This paper is a survey of the theory and methods of photogrammetric bundle adjustment, aimed at potential implementors in the computer vision community. Bundle adjustment is the problem of refining a visual reconstruction to produce jointly optimal structure and viewing parameter estimates. Topics covered include: the choice of cost function and robustness; numerical optimization including sparse Newton methods, linearly convergent approximations, updating and recursive methods; gauge (datum) invariance; and quality control. The theory is developed for general robust cost functions rather than restricting attention to traditional nonlinear least squares.}},
    address = {Berlin, Heidelberg},
    author = {Triggs, Bill and McLauchlan, Philip F. and Hartley, Richard I. and Fitzgibbon, Andrew W.},
    booktitle = {Vision Algorithms: Theory and Practice},
    chapter = {21},
    citeulike-article-id = {5971563},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-44480-7\_21},
    citeulike-linkout-1 = {http://www.springerlink.com/content/plvcrq5bx753a2tn},
    day = {12},
    editor = {Triggs, Bill and Zisserman, Andrew and Szeliski, Richard},
    isbn = {978-3-540-67973-8},
    journal = {Vision Algorithms: Theory and Practice},
    keywords = {ba, survey},
    month = apr,
    pages = {153--177},
    posted-at = {2012-02-16 23:23:13},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{Bundle Adjustment — A Modern Synthesis Vision Algorithms: Theory and Practice}},
    volume = {1883},
    year = {2000}
}

@inproceedings{AitAider2006Exploiting,
    abstract = {{An original method for computing instantaneous 3D pose and velocity of fast moving objects using a single view is presented. It exploits image deformations induced by rolling shutter in CMOS image sensors. First of all, a general perspective projection model of a moving 3D point is presented. A solution for the pose and velocity recovery problem is then described. The method is based on bundle adjustment and uses point correspondences. The resulting algorithm enables to transform a CMOS low cost and low power camera into an original velocity sensor. Finally, experimental results with real data confirm the relevance of the approach.}},
    author = {Ait-Aider, O. and Andreff, N. and Lavest, J. M. and Martinet, P.},
    booktitle = {Computer Vision Systems, 2006 ICVS '06. IEEE International Conference on},
    citeulike-article-id = {10360605},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICVS.2006.25},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1578723},
    institution = {Blaise Pascal University, France},
    isbn = {0-7695-2506-7},
    keywords = {distortion, rolling\_shutter},
    month = jan,
    pages = {35},
    posted-at = {2012-02-16 23:20:49},
    priority = {3},
    publisher = {IEEE},
    title = {{Exploiting Rolling Shutter Distortions for Simultaneous Object Pose and Velocity Computation Using a Single View}},
    year = {2006}
}

@article{Meingast2005Geometric,
    abstract = {{Cameras with rolling shutters are becoming more common as low-power, low-cost
CMOS sensors are being used more frequently in cameras. The rolling shutter
means that not all scanlines are exposed over the same time interval. The
effects of a rolling shutter are noticeable when either the camera or objects
in the scene are moving and can lead to systematic biases in projection
estimation. We develop a general projection equation for a rolling shutter
camera and show how it is affected by different types of camera motion. In the
case of fronto-parallel motion, we show how that camera can be modeled as an
X-slit camera. We also develop approximate projection equations for a non-zero
angular velocity about the optical axis and approximate the projection equation
for a constant velocity screw motion. We demonstrate how the rolling shutter
effects the projective geometry of the camera and in turn the
structure-from-motion.}},
    archivePrefix = {arXiv},
    author = {Meingast, Marci and Geyer, Christopher and Sastry, Shankar},
    citeulike-article-id = {10360604},
    citeulike-linkout-0 = {http://arxiv.org/abs/cs/0503076},
    citeulike-linkout-1 = {http://arxiv.org/pdf/cs/0503076},
    day = {29},
    eprint = {cs/0503076},
    keywords = {geometric, rolling\_shutter},
    month = mar,
    posted-at = {2012-02-16 23:19:53},
    priority = {2},
    title = {{Geometric Models of Rolling-Shutter Cameras}},
    year = {2005}
}

@article{Geman1984Stochastic,
    abstract = {{We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios.}},
    author = {Geman, Stuart and Geman, Donald},
    booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    citeulike-article-id = {5092278},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/TPAMI.1984.4767596},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4767596},
    comment = {The famous Geman \& Geman paper},
    day = {27},
    institution = {Division of Applied Mathematics, Brown University, Providence, RI 02912.},
    issn = {0162-8828},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {bayesian, gibbs, sampling},
    month = nov,
    number = {6},
    pages = {721--741},
    posted-at = {2012-02-15 05:23:03},
    priority = {2},
    publisher = {IEEE},
    title = {{Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images}},
    volume = {PAMI-6},
    year = {1984}
}

@inproceedings{Felzenszwalb2004Efficient,
    abstract = {{Markov random field models provide a robust and unified framework for early vision problems such as stereo, optical flow and image restoration. Inference algorithms based on graph cuts and belief propagation yield accurate results, but despite recent advances are often still too slow for practical use. In this paper we present new algorithmic techniques that substantially improve the running time of the belief propagation approach. One of our techniques reduces the complexity of the inference algorithm to be linear rather than quadratic in the number of possible labels for each pixel, which is important for problems such as optical flow or image restoration that have a large label set. A second technique makes it possible to obtain good results with a small fixed number of message passing iterations, independent of the size of the input images. Taken together these techniques speed up the standard algorithm by several orders of magnitude. In practice we obtain stereo, optical flow and image restoration algorithms that are as accurate as other global methods (e.g., using the Middlebury stereo benchmark) while being as fast as local techniques.}},
    author = {Felzenszwalb, P. F. and Huttenlocher, D. R.},
    booktitle = {Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on},
    citeulike-article-id = {224707},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2004.1315041},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1315041},
    institution = {Dept. of Comput. Sci., Cornell Univ., Ithaca, NY, USA},
    isbn = {0-7695-2158-4},
    issn = {1063-6919},
    journal = {Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on},
    keywords = {belief\_propagation, cv},
    month = jun,
    pages = {I-261--I-268 Vol.1},
    posted-at = {2012-02-15 04:49:20},
    priority = {4},
    publisher = {IEEE},
    title = {{Efficient belief propagation for early vision}},
    volume = {1},
    year = {2004}
}

@inproceedings{Scharstein2007Learning,
    abstract = {{State-of-the-art stereo vision algorithms utilize color changes as important cues for object boundaries. Most methods impose heuristic restrictions or priors on disparities, for example by modulating local smoothness costs with intensity gradients. In this paper we seek to replace such heuristics with explicit probabilistic models of disparities and intensities learned from real images. We have constructed a large number of stereo datasets with ground-truth disparities, and we use a subset of these datasets to learn the parameters of conditional random fields (CRFs). We present experimental results illustrating the potential of our approach for automatically learning the parameters of models with richer structure than standard hand-tuned MRF models.}},
    author = {Scharstein, D. and Pal, C.},
    booktitle = {Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on},
    citeulike-article-id = {10352767},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2007.383191},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4270216},
    institution = {Middlebury Coll., Middlebury},
    isbn = {1-4244-1180-7},
    keywords = {crf, stereo},
    month = jun,
    pages = {1--8},
    posted-at = {2012-02-15 01:14:49},
    priority = {2},
    publisher = {IEEE},
    title = {{Learning Conditional Random Fields for Stereo}},
    year = {2007}
}

@article{Atiyah2002Special,
    abstract = {{A survey is given of several key themes that have characterised mathematics in the 20th century. The impact of physics is also discussed, and some speculations are made about possible developments in the 21st century. 2000 Mathematics Subject Classification 00-02. 10.1112/S0024609301008566}},
    author = {Atiyah, Michael},
    citeulike-article-id = {6615704},
    citeulike-linkout-0 = {http://dx.doi.org/10.1112/S0024609301008566},
    citeulike-linkout-1 = {http://blms.oxfordjournals.org/cgi/content/abstract/34/1/1},
    day = {1},
    journal = {Bull. London Math. Soc.},
    keywords = {mathematics, survey},
    month = jan,
    number = {1},
    pages = {1--15},
    posted-at = {2012-02-15 00:54:18},
    priority = {3},
    title = {{Special Article Mathematics in the 20th Century}},
    volume = {34},
    year = {2002}
}

@article{Hong2004SegmentBased,
    abstract = {{In this paper, we present a new segment-based stereo  matching algorithm using graph cuts. In our approach, the  reference image is divided into non-overlapping homogeneous  segments and the scene structure is represented as  a set of planes in the disparity space. The stereo matching  problem is formulated as an energy minimization problem  in the segment domain instead of the traditional pixel domain.  Graph cuts technique is used to fast approximate the  optimal solution, which assigns the corresponding disparity  plane to each segment. Experiments demonstrate that the  performance of our algorithm is comparable to the state-of-the-art stereo algorithms on various data sets. Furthermore, strong performance is achieved in the conventionally difficult areas such as: textureless regions, disparity discontinuous boundaries and occluded portions.}},
    address = {Los Alamitos, CA, USA},
    author = {Hong, Li and Chen, George},
    citeulike-article-id = {10352445},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2004.220},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/CVPR.2004.220},
    issn = {1063-6919},
    journal = {Computer Vision and Pattern Recognition, IEEE Computer Society Conference on},
    keywords = {disparity, graph\_cut, segment, stereo},
    pages = {74--81},
    posted-at = {2012-02-14 22:41:14},
    priority = {3},
    publisher = {IEEE Computer Society},
    title = {{Segment-Based Stereo Matching Using Graph Cuts}},
    volume = {1},
    year = {2004}
}

@inproceedings{Scharstein2001Taxonomy,
    abstract = {{Stereo matching is one of the most active research areas in
computer vision. While a large number of algorithms for stereo
correspondence have been developed, relatively little work has been done
on characterizing their performance. In this paper, we present a
taxonomy of dense, two-frame stereo methods designed to assess the
different components and design decisions made in individual stereo
algorithms. Using this taxonomy, we compare existing stereo methods and
present experiments evaluating the performance of many different
variants. In order to establish a common software platform and a
collection of data sets for easy evaluation, we have designed a
stand-alone, flexible C++ implementation that enables the evaluation of
individual components and that can be easily extended to include new
algorithms. We have also produced several new multiframe stereo data
sets with ground truth, and are making both the code and data sets
available on the Web}},
    author = {Scharstein, D. and Szeliski, R. and Zabih, R.},
    booktitle = {Stereo and Multi-Baseline Vision, 2001. (SMBV 2001). Proceedings. IEEE Workshop on},
    citeulike-article-id = {126702},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/SMBV.2001.988771},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=988771},
    institution = {Dept. of Math \& Comp. Sci., Middlebury Coll., VT},
    isbn = {0-7695-1327-1},
    journal = {Stereo and Multi-Baseline Vision, 2001. (SMBV 2001). Proceedings. IEEE Workshop on},
    keywords = {disparity, stereo},
    location = {Kauai, HI, USA},
    pages = {131--140},
    posted-at = {2012-02-14 22:29:50},
    priority = {3},
    publisher = {IEEE},
    title = {{A taxonomy and evaluation of dense two-frame stereo correspondence
algorithms}},
    year = {2001}
}

@misc{Broder2002Network,
    abstract = {{A Bloom filter is an ingenious randomized data-structure for concisely representing a set in order to support approximate membership queries. The space efficiency is achieved at the cost of a small probability of false positives. It was invented by Burton Bloom in 1970 for the purpose of spell checking and for many years it was seldom mentioned in other contexts, except for database optimization. Nevertheless, Bloom's beautiful approach has seen a sudden resurgence in a variety of large-scale...}},
    author = {Broder, A. and Mitzenmacher, M.},
    citeulike-article-id = {1371118},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.20.98},
    keywords = {bloom\_filter, hashing, network},
    posted-at = {2012-02-14 19:33:53},
    priority = {2},
    title = {{Network Applications of Bloom Filters: A Survey}},
    year = {2002}
}

@inproceedings{Schmid1997Automatic,
    abstract = {{The paper presents a new method for matching individual line
segments between images. The method uses both grey-level information and
the multiple view geometric relations between the images. For image
pairs epipolar geometry facilitates the computation of a
cross-correlation based matching score for putative line
correspondences. For image triplets cross-correlation matching scores
are used in conjunction with line transfer based on the trifocal
geometry. Algorithms are developed for both short and long range motion.
In the case of long range motion the algorithm involves evaluating a one
parameter family of plane induced homographies. The algorithms are
robust to deficiencies in the line segment extraction and partial
occlusion. Experimental results are given for image pairs and triplets,
for varying motions between views, and for different scene types. The
three view algorithm eliminates all mismatches}},
    author = {Schmid, C. and Zisserman, A.},
    booktitle = {Computer Vision and Pattern Recognition, 1997. Proceedings., 1997 IEEE Computer Society Conference on},
    citeulike-article-id = {1994335},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.1997.609397},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=609397},
    institution = {Dept. of Eng. Sci., Oxford Univ.},
    isbn = {0-8186-7822-4},
    journal = {Computer Vision and Pattern Recognition, 1997. Proceedings., 1997 IEEE Computer Society Conference on},
    keywords = {line, matching, reconstruction},
    month = jun,
    pages = {666--671},
    posted-at = {2012-02-14 18:59:29},
    priority = {3},
    publisher = {IEEE},
    title = {{Automatic line matching across views}},
    year = {1997}
}

@inproceedings{Baillard99automaticline,
    author = {Baillard, C. and Schmid, C. and Zisserman, A. and Fitzgibbon, A. and England, Oxford O.},
    booktitle = {In ISPRS Conference on Automatic Extraction of GIS Objects from Digital Imagery, IAPRS vol.32, Part 3-2W5},
    citeulike-article-id = {10351232},
    keywords = {line, reconstruction},
    pages = {69--80},
    posted-at = {2012-02-14 18:52:09},
    priority = {3},
    title = {{Automatic line matching and 3D reconstruction of buildings from multiple views}},
    year = {1999}
}

@inproceedings{Klaus2006SegmentBased,
    abstract = {{A novel stereo matching algorithm is proposed that utilizes color segmentation on the reference image and a self-adapting matching score that maximizes the number of reliable correspondences. The scene structure is modeled by a set of planar surface patches which are estimated using a new technique that is more robust to outliers. Instead of assigning a disparity value to each pixel, a disparity plane is assigned to each segment. The optimal disparity plane labeling is approximated by applying belief propagation. Experimental results using the Middlebury stereo test bed demonstrate the superior performance of the proposed method}},
    address = {Washington, DC, USA},
    author = {Klaus, A. and Sormann, M. and Karner, K.},
    booktitle = {Pattern Recognition, 2006. ICPR 2006. 18th International Conference on},
    citeulike-article-id = {7663486},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1172671},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ICPR.2006.1033},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1699458},
    institution = {VRVis Res. Center, Graz},
    isbn = {0-7695-2521-0},
    issn = {1051-4651},
    keywords = {belief\_propagation, dissimilarity, measure, mvs},
    location = {Hong Kong, China},
    pages = {15--18},
    posted-at = {2012-02-14 15:57:43},
    priority = {4},
    publisher = {IEEE},
    series = {ICPR '06},
    title = {{Segment-Based Stereo Matching Using Belief Propagation and a Self-Adapting Dissimilarity Measure}},
    volume = {3},
    year = {2006}
}

@inproceedings{Ashikhmin2001Synthesizing,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Ashikhmin, Michael},
    booktitle = {Proceedings of the 2001 symposium on Interactive 3D graphics},
    citeulike-article-id = {1448227},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=581926},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/364338.364405},
    isbn = {1-58113-292-1},
    keywords = {texture},
    pages = {217--226},
    posted-at = {2012-02-14 03:19:20},
    priority = {4},
    publisher = {ACM},
    series = {I3D '01},
    title = {{Synthesizing natural textures}},
    year = {2001}
}

@article{amortizedcomplexity,
    author = {Tarjan, R. E.},
    citeulike-article-id = {2599849},
    journal = {SIAM Journal on Algebraic Discrete Methods},
    keywords = {amortized, complexity},
    month = apr,
    number = {2},
    pages = {306--318},
    posted-at = {2012-02-13 19:24:27},
    priority = {2},
    title = {{Amortized computational complexity}},
    volume = {6},
    year = {1985}
}

@article{Chazelle1986Fractional,
    abstract = {{This paper presents several applications of fractional cascading , a new searching technique which has been described in a companion paper. The applications center around a variety of geometric query problems. Examples include intersecting a polygonal path with a line, slanted range search, orthogonal range search, computing locus functions, and others. Some results on the optimality of fractional cascading, and certain extensions of the technique for retrieving additional information are also included.}},
    author = {Chazelle, Bernard and Guibas, Leonidas J.},
    citeulike-article-id = {10348310},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/BF01840441},
    citeulike-linkout-1 = {http://www.springerlink.com/content/j5028h162331u315},
    day = {1},
    issn = {0178-4617},
    journal = {Algorithmica},
    keywords = {fractional\_cascading, iterative\_search},
    month = nov,
    number = {1},
    pages = {163--191},
    posted-at = {2012-02-13 18:21:45},
    priority = {2},
    publisher = {Springer New York},
    title = {{Fractional cascading: II. Applications}},
    volume = {1},
    year = {1986}
}

@article{Chazelle1986Fractional,
    abstract = {{In computational geometry many search problems and range queries can be solved by performing an iterative search for the same key in separate ordered lists. In this paper we show that, if these ordered lists can be put in a one-to-one correspondence with the nodes of a graph of degree d so that the iterative search always proceeds along edges of that graph, then we can do much better than the obvious sequence of binary searches. Without expanding the storage by more than a constant factor, we can build a data-structure, called a fractional cascading structure , in which all original searches after the first can be carried out at only log d extra cost per search. Several results related to the dynamization of this structure are also presented. A companion paper gives numerous applications of this technique to geometric problems.}},
    author = {Chazelle, Bernard and Guibas, Leonidas J.},
    citeulike-article-id = {10347845},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/BF01840440},
    citeulike-linkout-1 = {http://www.springerlink.com/content/w00156688761426v},
    day = {1},
    issn = {0178-4617},
    journal = {Algorithmica},
    keywords = {fractional\_cascading, iterative\_search},
    month = nov,
    number = {1},
    pages = {133--162},
    posted-at = {2012-02-13 15:45:34},
    priority = {2},
    publisher = {Springer New York},
    title = {{Fractional cascading: I. A data structuring technique}},
    volume = {1},
    year = {1986}
}

@inproceedings{Efros1999Texture,
    abstract = {{A non-parametric method for texture synthesis is proposed. The
texture synthesis process grows a new image outward from an initial
seed, one pixel at a time. A Markov random field model is assumed, and
the conditional distribution of a pixel given all its neighbors
synthesized so far is estimated by querying the sample image and finding
all similar neighborhoods. The degree of randomness is controlled by a
single perceptually intuitive parameter. The method aims at preserving
as much local structure as possible and produces good results for a wide
variety of synthetic and real-world textures}},
    author = {Efros, A. A. and Leung, T. K.},
    booktitle = {Computer Vision, 1999. The Proceedings of the Seventh IEEE International Conference on},
    citeulike-article-id = {2938437},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/ICCV.1999.790383},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ICCV.1999.790383},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=790383},
    institution = {Comput. Sci. Div., California Univ., Berkeley, CA},
    isbn = {0-7695-0164-8},
    journal = {Computer Vision, 1999. The Proceedings of the Seventh IEEE International Conference on},
    keywords = {texture},
    location = {Kerkyra, Greece},
    pages = {1033--1038 vol.2},
    posted-at = {2012-02-13 15:23:44},
    priority = {2},
    publisher = {IEEE},
    title = {{Texture synthesis by non-parametric sampling}},
    volume = {2},
    year = {1999}
}

@article{Cornelis20083D,
    abstract = {{Supplying realistically textured 3D city models at ground level promises to be useful for pre-visualizing upcoming traffic situations in car navigation systems. Because this pre-visualization can be rendered from the expected future viewpoints of the driver, the required maneuver will be more easily understandable. 3D city models can be reconstructed from the imagery recorded by surveying vehicles. The vastness of image material gathered by these vehicles, however, puts extreme demands on vision algorithms to ensure their practical usability. Algorithms need to be as fast as possible and should result in compact, memory efficient 3D city models for future ease of distribution and visualization. For the considered application, these are not contradictory demands. Simplified geometry assumptions can speed up vision algorithms while automatically guaranteeing compact geometry models. In this paper, we present a novel city modeling framework which builds upon this philosophy to create 3D content at high speed.

Objects in the environment, such as cars and pedestrians, may however disturb the reconstruction, as they violate the simplified geometry assumptions, leading to visually unpleasant artifacts and degrading the visual realism of the resulting 3D city model. Unfortunately, such objects are prevalent in urban scenes. We therefore extend the reconstruction framework by integrating it with an object recognition module that automatically detects cars in the input video streams and localizes them in 3D. The two components of our system are tightly integrated and benefit from each other's continuous input. 3D reconstruction delivers geometric scene context, which greatly helps improve detection precision. The detected car locations, on the other hand, are used to instantiate virtual placeholder models which augment the visual realism of the reconstructed city model.}},
    address = {Hingham, MA, USA},
    author = {Cornelis, Nico and Leibe, Bastian and Cornelis, Kurt and Gool, Luc},
    citeulike-article-id = {10345472},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1355831},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s11263-007-0081-9},
    issn = {0920-5691},
    journal = {Int. J. Comput. Vision},
    keywords = {city, recognition, reconstruction, sfm, street},
    month = jul,
    pages = {121--141},
    posted-at = {2012-02-12 22:50:49},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {{3D Urban Scene Modeling Integrating Recognition and Reconstruction}},
    volume = {78},
    year = {2008}
}

@article{Szeliski1999Stereo,
    abstract = {{This paper formulates and solves a new variant of the stereo
correspondence problem: simultaneously recovering the disparities,
true colors, and opacities of visible surface elements. This problem
arises in newer applications of stereo reconstruction, such as view
interpolation and the layering of real imagery with synthetic graphics
for special effects and virtual studio applications. While this problem
is intrinsically more difficult than traditional stereo correspondence,
where only the disparities are being recovered, it provides a principled
way of dealing with commonly occurring problems such as occlusions and
the handling of mixed (foreground/background) pixels near depth
discontinuities. It also provides a novel means for separating
foreground and background objects (matting), without the use of a special
blue screen. We formulate the problem as the recovery of colors and
opacities in a generalized 3D (x, y, d) disparity 
space, and solve the
problem using a combination of initial evidence aggregation followed by
iterative energy minimization.}},
    address = {Hingham, MA, USA},
    author = {Szeliski, Richard and Golland, Polina},
    citeulike-article-id = {10338720},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=331273},
    citeulike-linkout-1 = {http://dx.doi.org/10.1023/A:1008192912624},
    issn = {0920-5691},
    journal = {Int. J. Comput. Vision},
    keywords = {matt, mvs, transparency},
    month = aug,
    pages = {45--61},
    posted-at = {2012-02-12 18:47:53},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {{Stereo Matching with Transparency and Matting}},
    volume = {32},
    year = {1999}
}

@inproceedings{Chen1993View,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Chen, Shenchang E. and Williams, Lance},
    booktitle = {Proceedings of the 20th annual conference on Computer graphics and interactive techniques},
    citeulike-article-id = {841656},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=166153},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/166117.166153},
    isbn = {0-89791-601-8},
    keywords = {synthesis, view\_interpolation},
    location = {Anaheim, CA},
    pages = {279--288},
    posted-at = {2012-02-12 16:34:13},
    priority = {2},
    publisher = {ACM},
    series = {SIGGRAPH '93},
    title = {{View interpolation for image synthesis}},
    year = {1993}
}

@article{Szeliski2006Image,
    abstract = {{This tutorial reviews image alignment and image stitching algorithms. Image alignment algorithms can discover the correspondence relationships among images with varying degrees of overlap. They are ideally suited for applications such as video stabilization, summarization, and the creation of panoramic mosaics. Image stitching algorithms take the alignment estimates produced by such registration algorithms and blend the images in a seamless manner, taking care to deal with potential problems such as blurring or ghosting caused by parallax and scene movement as well as varying image exposures. This tutorial reviews the basic motion models underlying alignment and stitching algorithms, describes effective direct (pixel-based) and feature-based alignment algorithms, and describes blending algorithms used to produce seamless mosaics. It ends with a discussion of open research problems in the area.}},
    address = {Hanover, MA, USA},
    author = {Szeliski, Richard},
    citeulike-article-id = {3578523},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1295185},
    citeulike-linkout-1 = {http://dx.doi.org/10.1561/0600000009},
    issn = {1572-2740},
    journal = {Found. Trends. Comput. Graph. Vis.},
    keywords = {alignment, lk, panorama, robust\_statistics, stitch},
    month = jan,
    number = {1},
    pages = {1--104},
    posted-at = {2012-02-12 15:34:33},
    priority = {2},
    publisher = {Now Publishers Inc.},
    title = {{Image alignment and stitching: a tutorial}},
    volume = {2},
    year = {2006}
}

@article{Szeliski1997SplineBased,
    abstract = {{The problem of image registration subsumes a number of problems and
techniques in multiframe image analysis, including the computation of optic
flow (general pixel-based motion), stereo correspondence,
structure from motion, and feature tracking.
We present a new registration algorithm based on 
spline representations
of the displacement field which can be specialized to solve
all of the above mentioned problems.  In particular, we show how to compute
local flow, global (parametric) flow, rigid flow resulting from camera
egomotion, and multiframe versions of the above problems.  
Using a spline-based description of the flow removes the need for
overlapping correlation windows, and produces an explicit measure of the
correlation between adjacent flow estimates.
We demonstrate our algorithm on multiframe image registration
and the recovery of 3D projective scene geometry.
We also provide results on a number of standard motion sequences.}},
    address = {Hingham, MA, USA},
    author = {Szeliski, Richard and Coughlan, James},
    citeulike-article-id = {2639272},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=254734},
    citeulike-linkout-1 = {http://dx.doi.org/10.1023/A:1007996332012},
    issn = {0920-5691},
    journal = {Int. J. Comput. Vision},
    keywords = {mvs, registration, spline},
    month = mar,
    pages = {199--218},
    posted-at = {2012-02-11 03:26:06},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {{Spline-Based Image Registration}},
    volume = {22},
    year = {1997}
}

@inproceedings{Szeliski1998Stereo,
    abstract = {{This paper formulates and solves a new variant of the stereo
correspondence problem: simultaneously recovering the disparities, true
colors, and opacities of visible surface elements. This problem arises
in newer applications of stereo reconstruction, such as view
interpolation and the layering of real imagery with synthetic graphics
for special effects and virtual studio applications. While this problem
is intrinsically more difficult than traditional stereo correspondence,
where only the disparities are being recovered, it provides a principled
way of dealing with commonly occurring problems such as occlusions and
the handling of mixed (foreground/background) pixels near depth
discontinuities. It also provides a novel means for separating
foreground and background objects (matting), without the use of a
special blue screen. We formulate the problem as the recovery of colors
and opacities in a generalized 3-D (x, y, d) disparity space, and solve
the problem using a combination of initial evidence aggregation followed
by iterative energy minimization}},
    author = {Szeliski, R. and Golland, P.},
    booktitle = {Computer Vision, 1998. Sixth International Conference on},
    citeulike-article-id = {10330740},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICCV.1998.710766},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=710766},
    institution = {Microsoft Corp., Redmond, WA},
    isbn = {81-7319-221-9},
    keywords = {mvs},
    month = jan,
    pages = {517--524},
    posted-at = {2012-02-10 00:57:37},
    priority = {2},
    publisher = {IEEE},
    title = {{Stereo matching with transparency and matting}},
    year = {1998}
}

@inproceedings{Seitz1997Photorealistic,
    abstract = {{A novel scene reconstruction technique is presented, different
from previous approaches in its ability to cope with large changes in
visibility and its modeling of intrinsic scene color and texture
information. The method avoids image correspondence problems by working
in a discretized scene space whose voxels are traversed in a fixed
visibility ordering. This strategy takes full account of occlusions and
allows the input cameras to be far apart and widely distributed about
the environment. The algorithm identifies a special set of invariant
voxels which together form a spatial and photometric reconstruction of
the scene, fully consistent with the input images. The approach is
evaluated with images from both inward- and outward-facing cameras}},
    author = {Seitz, S. M. and Dyer, C. R.},
    booktitle = {Computer Vision and Pattern Recognition, 1997. Proceedings., 1997 IEEE Computer Society Conference on},
    citeulike-article-id = {10330733},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.1997.609462},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=609462},
    institution = {Dept. of Comput. Sci., Wisconsin Univ., Madison, WI},
    isbn = {0-8186-7822-4},
    keywords = {mvs, reconstruction, voxel},
    month = jun,
    pages = {1067--1073},
    posted-at = {2012-02-10 00:56:31},
    priority = {2},
    publisher = {IEEE},
    title = {{Photorealistic scene reconstruction by voxel coloring}},
    year = {1997}
}

@inproceedings{Karger1997Consistent,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Karger, David and Lehman, Eric and Leighton, Tom and Panigrahy, Rina and Levine, Matthew and Lewin, Daniel},
    booktitle = {Proceedings of the twenty-ninth annual ACM symposium on Theory of computing},
    citeulike-article-id = {4303},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=258660},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/258533.258660},
    isbn = {0-89791-888-6},
    keywords = {distributed, hashing},
    location = {El Paso, Texas, United States},
    pages = {654--663},
    posted-at = {2012-02-09 22:53:23},
    priority = {2},
    publisher = {ACM},
    series = {STOC '97},
    title = {{Consistent hashing and random trees: distributed caching protocols for relieving hot spots on the World Wide Web}},
    year = {1997}
}

@inproceedings{Kang2001Handling,
    abstract = {{While stereo matching was originally formulated as the recovery of 3D shape from a pair of images, it is now generally recognized that using more than two images can dramatically improve the quality of the reconstruction. Unfortunately, as more images are added, the prevalence of semi-occluded regions (pixels visible in some but not all images) also increases. We propose some novel techniques to deal with this problem. Our first idea is to use a combination of shiftable windows and a dynamically selected subset of the neighboring images to do the matches. Our second idea is to explicitly label occluded pixels within a global energy minimization framework, and to reason about visibility within this framework so that only truly visible pixels are matched. Experimental results show a dramatic improvement using the first idea over conventional multibaseline stereo, especially when used in conjunction with a global energy minimization technique. These results also show that explicit occlusion labeling and visibility reasoning do help, but not significantly, if the spatial and temporal selection is applied first.}},
    author = {Kang, Sing B. and Szeliski, R. and Chai, Jinxiang},
    booktitle = {Computer Vision and Pattern Recognition, 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on},
    citeulike-article-id = {7676590},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2001.990462},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=990462},
    institution = {Microsoft Res., Microsoft Corp., Redmond, WA, USA},
    isbn = {0-7695-1272-0},
    issn = {1063-6919},
    keywords = {dense, mvs, occlusion},
    location = {Kauai, HI, USA},
    pages = {I-103--I-110 vol.1},
    posted-at = {2012-02-09 18:02:16},
    priority = {2},
    publisher = {IEEE},
    title = {{Handling occlusions in dense multi-view stereo}},
    volume = {1},
    year = {2001}
}

@techreport{Furukawa2006HighFidelity,
    author = {Furukawa, Yasutaka and Ponce, Jean},
    citeulike-article-id = {10328391},
    citeulike-linkout-0 = {http://www.cs.washington.edu/homes/furukawa/papers/cvr\_tr\_2006\_02.pdf},
    comment = {(private-note)http://research.microsoft.com/apps/video/default.aspx?id=131805},
    keywords = {mvs, pmvs},
    month = feb,
    posted-at = {2012-02-09 03:54:48},
    priority = {2},
    title = {{High-Fidelity Image Based Modeling}},
    year = {2006}
}

@inproceedings{Szeliski1999Multiview,
    abstract = {{This paper presents a new approach to computing dense depth and
motion estimates from multiple images. Rather than computing a single
depth or motion map from such a collection, we associate motion or depth
estimates with each image in the collection (or at least some subset of
the images). This has the advantage that the depth or motion of regions
occluded in one image will still be represented in some other image.
Thus, tasks such as novel view interpolation or motion-compensated
prediction can be solved with greater fidelity. Furthermore, the natural
variation in appearance between different images can be captured. To
formulate motion and structure recovery, we cast the problem as a global
optimization over the unknown motion or depth maps, and use robust
smoothness constraints to constrain the space of possible solutions. We
develop and evaluate some motion and depth estimation algorithms based
on this framework}},
    author = {Szeliski, R.},
    booktitle = {Computer Vision and Pattern Recognition, 1999. IEEE Computer Society Conference on.},
    citeulike-article-id = {10328339},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.1999.786933},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=786933},
    institution = {Microsoft Corp., Redmond, WA},
    isbn = {0-7695-0149-4},
    keywords = {mvs},
    pages = {163 Vol. 1},
    posted-at = {2012-02-09 02:07:13},
    priority = {2},
    publisher = {IEEE},
    title = {{A multi-view approach to motion and stereo}},
    volume = {1},
    year = {1999}
}

@inproceedings{Seitz2006Comparison,
    abstract = {{This paper presents a quantitative comparison of several multi-view stereo reconstruction algorithms. Until now, the lack of suitable calibrated multi-view image datasets with known ground truth (3D shape models) has prevented such direct comparisons. In this paper, we first survey multi-view stereo algorithms and compare them qualitatively using a taxonomy that differentiates their key properties. We then describe our process for acquiring and calibrating multiview image datasets with high-accuracy ground truth and introduce our evaluation methodology. Finally, we present the results of our quantitative comparison of state-of-the-art multi-view stereo reconstruction algorithms on six benchmark datasets. The datasets, evaluation details, and instructions for submitting new models are available online at http://vision.middlebury.edu/mview.}},
    address = {Washington, DC, USA},
    author = {Seitz, S. M. and Curless, B. and Diebel, J. and Scharstein, D. and Szeliski, R.},
    booktitle = {Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on},
    citeulike-article-id = {800904},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1153518},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/CVPR.2006.19},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1640800},
    citeulike-linkout-3 = {http://csdl2.computer.org/persagen/DLAbsToc.jsp?resourcePath=/dl/proceedings/cvpr/\&\#38;toc=comp/proceedings/cvpr/2006/2597/01/2597toc.xml\&\#38;DOI=10.1109/CVPR.2006.19},
    institution = {University of Washington},
    isbn = {0-7695-2597-0},
    issn = {1063-6919},
    keywords = {mvs, photo\_consistency, reconstruction, visibility},
    month = jun,
    pages = {519--528},
    posted-at = {2012-02-09 02:02:45},
    priority = {2},
    publisher = {IEEE},
    title = {{A Comparison and Evaluation of Multi-View Stereo Reconstruction Algorithms}},
    volume = {1},
    year = {2006}
}

@article{Kingman1978Uses,
    author = {Kingman, J. F. C.},
    citeulike-article-id = {8151194},
    citeulike-linkout-0 = {http://dx.doi.org/10.1214/aop/1176995566},
    issn = {0091-1798},
    journal = {The Annals of Probability},
    keywords = {exchangeability, ml, probability, statistics},
    month = apr,
    number = {2},
    pages = {183--197},
    posted-at = {2012-02-08 20:59:38},
    priority = {2},
    title = {{Uses of Exchangeability}},
    volume = {6},
    year = {1978}
}

@article{Lee2007Caricature,
    abstract = {{We make moving caricatures from videos on human faces. Using training images, we created a 3D model of an average face. This allows us to transform the image in each frame of an input video, so that it is seen from the front. Then we apply 2D exaggeration rules to caricature each face. Finally, we rotate the face in each frame back to its original position. A panel of viewers gave positive scores to a series of test videos. Copyright {\copyright} 2007 John Wiley \& Sons, Ltd.}},
    author = {Lee, Eun-Jung and Kwon, Ji-yong and Lee, In-Kwon},
    citeulike-article-id = {1789075},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/cav.200},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/jws/cav/2007/00000018/F0020004/art00007},
    issn = {1546-4261},
    journal = {Comp. Anim. Virtual Worlds},
    keywords = {caricature, face, video},
    month = sep,
    number = {4-5},
    pages = {279--288},
    posted-at = {2012-02-08 19:43:21},
    priority = {2},
    publisher = {John Wiley \& Sons, Ltd.},
    title = {{Caricature video}},
    volume = {18},
    year = {2007}
}

@article{Woodford2009Global,
    abstract = {{Second-order priors on the smoothness of 3D surfaces are a better model of typical scenes than first-order priors. However, stereo reconstruction using global inference algorithms, such as graph cuts, has not been able to incorporate second-order priors because the triple cliques needed to express them yield intractable (nonsubmodular) optimization problems. This paper shows that inference with triple cliques can be effectively performed. Our optimization strategy is a development of recent extensions to alpha-expansion, based on the ldquo QPBOrdquo algorithm. The strategy is to repeatedly merge proposal depth maps using a novel extension of QPBO. Proposal depth maps can come from any source, for example, frontoparallel planes as in alpha-expansion, or indeed any existing stereo algorithm, with arbitrary parameter settings.}},
    address = {Washington, DC, USA},
    author = {Woodford, O. and Torr, P. and Reid, I. and Fitzgibbon, A.},
    citeulike-article-id = {6012230},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1638615.1639291},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/TPAMI.2009.131},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5128908},
    day = {26},
    issn = {0162-8828},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {prior, reconstruction, smooth},
    month = dec,
    number = {12},
    pages = {2115--2128},
    posted-at = {2012-02-08 15:21:21},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {{Global Stereo Reconstruction under Second-Order Smoothness Priors}},
    volume = {31},
    year = {2009}
}

@article{Chan02mathematicalmodels,
    author = {Chan, Tony F. and Shen, Jianhong},
    citeulike-article-id = {10325267},
    journal = {SIAM J. Appl. Math},
    keywords = {hole, texture},
    pages = {1019--1043},
    posted-at = {2012-02-08 03:18:08},
    priority = {2},
    title = {{Mathematical Models for Local Nontexture Inpaintings}},
    volume = {62},
    year = {2002}
}

@article{Frueh2005Data,
    abstract = {{In this paper, we develop a set of data processing algorithms for generating textured facade meshes of cities from a series of vertical 2D surface scans and camera images, obtained by a laser scanner and digital camera while driving on public roads under normal traffic conditions. These processing steps are needed to cope with imperfections and non-idealities inherent in laser scanning systems such as occlusions and reflections from glass surfaces. The data is divided into easy-to-handle quasi-linear segments corresponding to approximately straight driving direction and sequential topological order of vertical laser scans; each segment is then transformed into a depth image. Dominant building structures are detected in the depth images, and points are classified into foreground and background layers. Large holes in the background layer, caused by occlusion from foreground layer objects, are filled in by planar or horizontal interpolation. The depth image is further processed by removing isolated points and filling remaining small holes. The foreground objects also leave holes in the texture of building facades, which are filled by horizontal and vertical interpolation in low frequency regions, or by a copy-paste method otherwise. We apply the above steps to a large set of data of downtown Berkeley with several million 3D points, in order to obtain texture-mapped 3D models.}},
    address = {Hingham, MA, USA},
    author = {Frueh, Christian and Jain, Siddharth and Zakhor, Avideh},
    citeulike-article-id = {10325245},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1026574.1026582},
    citeulike-linkout-1 = {http://dx.doi.org/10.1023/B:VISI.0000043756.03810.dd},
    citeulike-linkout-2 = {http://www.springerlink.com/content/n726335pw4j27441},
    day = {1},
    issn = {0920-5691},
    journal = {International Journal of Computer Vision},
    keywords = {city, laser},
    month = feb,
    number = {2},
    pages = {159--184},
    posted-at = {2012-02-08 02:53:05},
    priority = {3},
    publisher = {Springer Netherlands},
    title = {{Data Processing Algorithms for Generating Textured 3D Building Facade Meshes from Laser Scans and Camera Images}},
    volume = {61},
    year = {2005}
}

@inproceedings{Micusik2009Piecewise,
    abstract = {{City environments often lack textured areas, contain repetitive structures, strong lighting changes and therefore are very difficult for standard 3D modeling pipelines. We present a novel unified framework for creating 3D city models which overcomes these difficulties by exploiting image segmentation cues as well as presence of dominant scene orientations and piecewise planar structures. Given panoramic street view sequences, we first demonstrate how to robustly estimate camera poses without a need for bundle adjustment and propose a multi-view stereo method which operates directly on panoramas, while enforcing the piecewise planarity constraints in the sweeping stage. At last, we propose a new depth fusion method which exploits the constraints of urban environments and combines advantages of volumetric and viewpoint based fusion methods. Our technique avoids expensive voxelization of space, operates directly on 3D reconstructed points through effective kd-tree representation, and obtains a final surface by tessellation of backprojections of those points into the reference image.}},
    author = {Micusik, B. and Kosecka, J.},
    booktitle = {Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
    citeulike-article-id = {7206521},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2009.5206535},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5206535},
    institution = {Comput. Sci. Dept., George Mason Univ., Fairfax, VA, USA},
    isbn = {978-1-4244-3992-8},
    issn = {1063-6919},
    keywords = {city, large\_scale, panorama, street},
    location = {Miami, FL},
    month = jun,
    pages = {2906--2912},
    posted-at = {2012-02-08 02:34:07},
    priority = {2},
    publisher = {IEEE},
    title = {{Piecewise planar city 3D modeling from street view panoramic sequences}},
    year = {2009}
}

@inproceedings{Furukawa2010Towards,
    abstract = {{This paper introduces an approach for enabling existing multi-view stereo methods to operate on extremely large unstructured photo collections. The main idea is to decompose the collection into a set of overlapping sets of photos that can be processed in parallel, and to merge the resulting reconstructions. This overlapping clustering problem is formulated as a constrained optimization and solved iteratively. The merging algorithm, designed to be parallel and out-of-core, incorporates robust filtering steps to eliminate low-quality reconstructions and enforce global visibility constraints. The approach has been tested on several large datasets downloaded from Flickr.com, including one with over ten thousand images, yielding a 3D reconstruction with nearly thirty million points.}},
    address = {Los Alamitos, CA, USA},
    author = {Furukawa, Y. and Curless, B. and Seitz, S. M. and Szeliski, R.},
    booktitle = {Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on},
    citeulike-article-id = {8212497},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2010.5539802},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/CVPR.2010.5539802},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5539802},
    comment = {(private-note)"It becomes important to select the right subset of images and to cluster them into manageable pieces."

PMVS is not feasible as the number of images grows.},
    isbn = {978-1-4244-6984-0},
    issn = {1063-6919},
    journal = {Computer Vision and Pattern Recognition, IEEE Computer Society Conference on},
    keywords = {large\_scale, mvs},
    location = {San Francisco, CA, USA},
    month = jun,
    pages = {1434--1441},
    posted-at = {2012-02-08 01:48:29},
    priority = {3},
    publisher = {IEEE},
    title = {{Towards Internet-scale multi-view stereo}},
    volume = {0},
    year = {2010}
}

@inproceedings{Zebedin2008Fusion,
    abstract = {{Accurate and realistic building models of urban environments are increasingly important for applications, like virtual tourism or city planning. Initiatives like Virtual Earth or Google Earth are aiming at offering virtual models of all major cities world wide. The prohibitively high costs of manual generation of such models explain the need for an automatic workflow.This paper proposes an algorithm for fully automatic building reconstruction from aerial images. Sparse line features delineating height discontinuities and dense depth data providing the roof surface are combined in an innovative manner with a global optimization algorithm based on Graph Cuts. The fusion process exploits the advantages of both information sources and thus yields superior reconstruction results compared to the indiviual sources. The nature of the algorithm also allows to elegantly generate image driven levels of detail of the geometry.The algorithm is applied to a number of real world data sets encompassing thousands of buildings. The results are analyzed in detail and extensively evaluated using ground truth data.}},
    address = {Berlin, Heidelberg},
    author = {Zebedin, Lukas and Bauer, Joachim and Karner, Konrad and Bischof, Horst},
    booktitle = {Proceedings of the 10th European Conference on Computer Vision: Part IV},
    citeulike-article-id = {5815167},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1502494},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-88693-8\_64},
    citeulike-linkout-2 = {http://www.springerlink.com/content/a83p7770g7m20x1r},
    isbn = {978-3-540-88692-1},
    journal = {Computer Vision – ECCV 2008},
    keywords = {aerial, city, reconstruction},
    location = {Marseille, France},
    pages = {873--886},
    posted-at = {2012-02-08 01:39:04},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {{Fusion of Feature- and Area-Based Information for Urban Buildings Modeling from Aerial Imagery}},
    year = {2008}
}

@article{Fruh2004Automated,
    abstract = {{In this paper, we describe an automated method for fast, ground-based acquisition of large-scale 3D city models. Our experimental set up consists of a truck equipped with one camera and two fast, inexpensive 2D laser scanners, being driven on city streets under normal traffic conditions. One scanner is mounted vertically to capture building facades, and the other one is mounted horizontally. Successive horizontal scans are matched with each other in order to determine an estimate of the vehicle's motion, and relative motion estimates are concatenated to form an initial path. Assuming that features such as buildings are visible from both ground-based and airborne view, this initial path is globally corrected by Monte-Carlo Localization techniques. Specifically, the final global pose is obtained by utilizing an aerial photograph or a Digital Surface Model as a global map, to which the ground-based horizontal laser scans are matched. A fairly accurate, textured 3D cof the downtown Berkeley area has been acquired in a matter of minutes, limited only by traffic conditions during the data acquisition phase. Subsequent automated processing time to accurately localize the acquisition vehicle is 235 minutes for a 37 minutes or 10.2 km drive, i.e. 23 minutes per kilometer.}},
    address = {Hingham, MA, USA},
    author = {Fr\"{u}h, Christian and Zakhor, Avideh},
    citeulike-article-id = {10323343},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=990399},
    citeulike-linkout-1 = {http://dx.doi.org/10.1023/B:VISI.0000027787.82851.b6},
    comment = {(private-note)Monte-Calo-Localization = MCL = particle filtering = condensation algorithm
---=note-separator=---
(private-note)- line based ICP
- Global Edge Map
- Particle Filter
- MVS to get the reconstruction},
    issn = {0920-5691},
    journal = {Int. J. Comput. Vision},
    keywords = {city, large\_scale, street},
    month = oct,
    pages = {5--24},
    posted-at = {2012-02-07 21:48:29},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {{An Automated Method for Large-Scale, Ground-Based City Model Acquisition}},
    volume = {60},
    year = {2004}
}

@inproceedings{GallupHeightmap,
    author = {Gallup, David and michael Frahm, Jan and Pollefeys, Marc},
    booktitle = {3DPVT (2010},
    citeulike-article-id = {10319893},
    keywords = {hightmap, reconstruction, street},
    posted-at = {2012-02-07 03:53:55},
    priority = {2},
    title = {{A heightmap model for efficient 3d reconstruction from street-level video}}
}

@inproceedings{Frahm2010Building,
    abstract = {{This paper introduces an approach for dense 3D reconstruction from unregistered Internet-scale photo collections with about 3 million images within the span of a day on a single PC ("cloudless"). Our method advances image clustering, stereo, stereo fusion and structure from motion to achieve high computational performance. We leverage geometric and appearance constraints to obtain a highly parallel implementation on modern graphics processors and multi-core architectures. This leads to two orders of magnitude higher performance on an order of magnitude larger dataset than competing state-of-the-art approaches.}},
    address = {Berlin, Heidelberg},
    author = {Frahm, Jan M. and Georgel, Pierre F. and Gallup, David and Johnson, Tim and Raguram, Rahul and Wu, Changchang and Jen, Yi H. and Dunn, Enrique and Clipp, Brian and Lazebnik, Svetlana and Pollefeys, Marc},
    booktitle = {Proceedings of the 11th European conference on Computer vision: Part IV},
    citeulike-article-id = {9333782},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1888117},
    isbn = {3-642-15560-X, 978-3-642-15560-4},
    keywords = {gpu, sfm},
    location = {Heraklion, Crete, Greece},
    pages = {368--381},
    posted-at = {2012-02-07 03:33:31},
    priority = {2},
    publisher = {Springer-Verlag},
    series = {ECCV'10},
    title = {{Building Rome on a cloudless day}},
    year = {2010}
}

@article{Furukawa2010Accurate,
    abstract = {{This paper proposes a novel algorithm for multiview stereopsis that outputs a dense set of small rectangular patches covering the surfaces visible in the images. Stereopsis is implemented as a match, expand, and filter procedure, starting from a sparse set of matched keypoints, and repeatedly expanding these before using visibility constraints to filter away false matches. The keys to the performance of the proposed algorithm are effective techniques for enforcing local photometric consistency and global visibility constraints. Simple but effective methods are also proposed to turn the resulting patch model into a mesh which can be further refined by an algorithm that enforces both photometric consistency and regularization constraints. The proposed approach automatically detects and discards outliers and obstacles and does not require any initialization in the form of a visual hull, a bounding box, or valid depth ranges. We have tested our algorithm on various data sets including objects with fine surface details, deep concavities, and thin structures, outdoor scenes observed from a restricted set of viewpoints, and "crowded" scenes where moving obstacles appear in front of a static structure of interest. A quantitative evaluation on the Middlebury benchmark [1] shows that the proposed method outperforms all others submitted so far for four out of the six data sets.}},
    address = {Los Alamitos, CA, USA},
    author = {Furukawa, Y. and Ponce, J.},
    citeulike-article-id = {7268694},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/TPAMI.2009.161},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/TPAMI.2009.161},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5226635},
    institution = {Google Inc., Seattle, WA, USA},
    issn = {0162-8828},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {dense, mvs, pmvs},
    month = aug,
    number = {8},
    pages = {1362--1376},
    posted-at = {2012-02-07 03:22:20},
    priority = {2},
    publisher = {IEEE},
    title = {{Accurate, Dense, and Robust Multiview Stereopsis}},
    volume = {32},
    year = {2010}
}

@inproceedings{Agarwal2010Bundle,
    abstract = {{We present the design and implementation of a new inexact Newton type algorithm for solving large-scale bundle adjustment problems with tens of thousands of images. We explore the use of Conjugate Gradients for calculating the Newton step and its performance as a function of some simple and computationally efficient preconditioners. We show that the common Schur complement trick is not limited to factorization-based methods and that it can be interpreted as a form of preconditioning. Using photos from a street-side dataset and several community photo collections, we generate a variety of bundle adjustment problems and use them to evaluate the performance of six different bundle adjustment algorithms. Our experiments show that truncated Newton methods, when paired with relatively simple preconditioners, offer state of the art performance for large-scale bundle adjustment. The code, test problems and detailed performance data are available at http://grail.cs.washington.edu/projects/bal.}},
    address = {Berlin, Heidelberg},
    author = {Agarwal, Sameer and Snavely, Noah and Seitz, Steven M. and Szeliski, Richard},
    booktitle = {Proceedings of the 11th European conference on Computer vision: Part II},
    citeulike-article-id = {10319770},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1888032},
    isbn = {3-642-15551-0, 978-3-642-15551-2},
    keywords = {ba, sfm},
    location = {Heraklion, Crete, Greece},
    pages = {29--42},
    posted-at = {2012-02-07 02:55:31},
    priority = {4},
    publisher = {Springer-Verlag},
    series = {ECCV'10},
    title = {{Bundle adjustment in the large}},
    year = {2010}
}

@inproceedings{Snavely2008Skeletal,
    abstract = {{We address the problem of efficient structure from motion for large, unordered, highly redundant, and irregularly sampled photo collections, such as those found on Internet photo-sharing sites. Our approach computes a small skeletal subset of images, reconstructs the skeletal set, and adds the remaining images using pose estimation. Our technique drastically reduces the number of parameters that are considered, resulting in dramatic speedups, while provably approximating the covariance of the full set of parameters. To compute a skeletal image set, we first estimate the accuracy of two-frame reconstructions between pairs of overlapping images, then use a graph algorithm to select a subset of images that, when reconstructed, approximates the accuracy of the full set. A final bundle adjustment can then optionally be used to restore any loss of accuracy.}},
    author = {Snavely, N. and Seitz, S. M. and Szeliski, R.},
    booktitle = {Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on},
    citeulike-article-id = {9861033},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/CVPR.2008.4587678},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4587678},
    institution = {Washington Univ., Seattle, WA},
    isbn = {978-1-4244-2242-5},
    issn = {1063-6919},
    keywords = {sfm},
    month = jun,
    pages = {1--8},
    posted-at = {2012-02-07 02:50:05},
    priority = {3},
    publisher = {IEEE},
    title = {{Skeletal graphs for efficient structure from motion}},
    year = {2008}
}

@inproceedings{Triggs2000Bundle,
    abstract = {{This paper is a survey of the theory and methods of photogrammetric bundle adjustment, aimed at potential implementors in the computer vision community. Bundle adjustment is the problem of refining a visual reconstruction to produce jointly optimal structure and viewing parameter estimates. Topics covered include: the choice of cost function and robustness; numerical optimization including sparse Newton methods, linearly convergent approximations, updating and recursive methods; gauge (datum) invariance; and quality control. The theory is developed for general robust cost functions rather than restricting attention to traditional nonlinear least squares.}},
    address = {London, UK},
    author = {Triggs, Bill and McLauchlan, Philip F. and Hartley, Richard I. and Fitzgibbon, Andrew W.},
    booktitle = {Proceedings of the International Workshop on Vision Algorithms: Theory and Practice},
    citeulike-article-id = {1576518},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=685629},
    isbn = {3-540-67973-1},
    keywords = {ba, sfm},
    pages = {298--372},
    posted-at = {2012-02-07 02:43:35},
    priority = {3},
    publisher = {Springer-Verlag},
    series = {ICCV '99},
    title = {{Bundle Adjustment - A Modern Synthesis}},
    year = {2000}
}

@inproceedings{HundtLoop,
    author = {Hundt, Robert},
    citeulike-article-id = {10319713},
    citeulike-linkout-0 = {http://static.googleusercontent.com/external\_content/untrusted\_dlcp/research.google.com/en/us/pubs/archive/37122.pdf},
    keywords = {cpp, go, java, performance, scala},
    posted-at = {2012-02-07 02:23:31},
    priority = {2},
    title = {{Loop Recognition in C++/Java/Go/Scala}},
}

@article{Agarwal2011Building,
    abstract = {{We present a system that can reconstruct 3D geometry from large, unorganized collections of photographs such as those found by searching for a given city (e.g., Rome) on Internet photo-sharing sites. Our system is built on a set of new, distributed computer vision algorithms for image matching and 3D reconstruction, designed to maximize parallelism at each stage of the pipeline and to scale gracefully with both the size of the problem and the amount of available computation. Our experimental results demonstrate that it is now possible to reconstruct city-scale image collections with more than a hundred thousand images in less than a day.}},
    address = {New York, NY, USA},
    author = {Agarwal, Sameer and Furukawa, Yasutaka and Snavely, Noah and Simon, Ian and Curless, Brian and Seitz, Steven M. and Szeliski, Richard},
    citeulike-article-id = {9913853},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2001293},
    citeulike-linkout-1 = {http://dblp.uni-trier.de/rec/bibtex/journals/cacm/AgarwalFSSCSS11},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/2001269.2001293},
    comment = {(private-note)Methods used: SIFT, ANN, RANSEC
---=note-separator=---
(private-note)City-scale 3D reconstruction has been explored previously. However, existing large scale systems operate o data that comes from a structured scorch, e.g., aerial photographs taken by a survey aircraft or street side imagery captured by a moving vehicle.
---=note-separator=---
(private-note)SfM gets the sparse distinctive image feature structure and the camera pose. MVS is used to recover the accurate models},
    issn = {0001-0782},
    journal = {Commun. ACM},
    keywords = {mvs, rome, sfm},
    month = oct,
    number = {10},
    pages = {105--112},
    posted-at = {2012-02-06 21:59:37},
    priority = {3},
    publisher = {ACM},
    title = {{Building Rome in a day}},
    volume = {54},
    year = {2011}
}

@book{Queinnec1996Lisp,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Queinnec, Christian},
    citeulike-article-id = {10315776},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=237851},
    comment = {(private-note)interesting code: p177},
    isbn = {0-521-56247-3},
    keywords = {compiler, lambda, lisp, scheme},
    posted-at = {2012-02-05 05:12:24},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {{Lisp in small pieces}},
    year = {1996}
}

@book{Gordon1993Programming,
    abstract = {{An abstract is not available.}},
    address = {Upper Saddle River, NJ, USA},
    author = {Gordon, Michael J.},
    citeulike-article-id = {10315772},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=529613},
    isbn = {0137304099},
    keywords = {functional, lambda, language, programming},
    posted-at = {2012-02-05 04:47:56},
    priority = {2},
    publisher = {Prentice-Hall, Inc.},
    title = {{Programming Language Theory and Its Implementation}},
    year = {1993}
}

@article{Boehm2012You,
    abstract = {{Data races are evil.}},
    address = {New York, NY, USA},
    author = {Boehm, Hans J. and Adve, Sarita V.},
    citeulike-article-id = {10312254},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2076465},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2076450.2076465},
    issn = {0001-0782},
    journal = {Commun. ACM},
    keywords = {memory, multithread, shared\_variables},
    month = feb,
    number = {2},
    pages = {48--54},
    posted-at = {2012-02-03 20:09:00},
    priority = {2},
    publisher = {ACM},
    title = {{You don't know jack about shared variables or memory models}},
    volume = {55},
    year = {2012}
}

@inproceedings{Jones1995Functional,
    abstract = {{. The Hindley/Milner type system has been widely adopted as

a basis for statically typed functional languages. One of the main reasons

for this is that it provides an elegant compromise between flexibility, allowing

a single value to be used in different ways, and practicality, freeing

the programmer from the need to supply explicit type information.

Focusing on practical applications rather than implementation or theoretical

details, these notes examine a range of extensions that
...}},
    author = {Jones, Mark P.},
    booktitle = {Advanced Functional Programming},
    citeulike-article-id = {386121},
    citeulike-linkout-0 = {http://dx.doi.org/10.1017/S0956796800001210},
    citeulike-linkout-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.26.9460},
    keywords = {functional, lambda, monad, overloading, polymorphism, programming, transformer},
    pages = {97--136},
    posted-at = {2012-01-31 04:28:08},
    priority = {2},
    title = {{Functional Programming with Overloading and Higher-Order Polymorphism}},
    year = {1995}
}

@inproceedings{Launchbury1994Lazy,
    abstract = {{Some algorithms make critical internal use of updatable state, even though their external specification is purely functional. Based on earlier work on monads, we present a way of securely encapsulating stateful computations that manipulate multiple, named, mutable objects, in the context of a non-strict, purely-functional language.The security of the encapsulation is assured by the type system, using parametricity. Intriguingly, this parametricity requires the provision of a (single) constant with a rank-2 polymorphic type.}},
    address = {New York, NY, USA},
    author = {Launchbury, John and Peyton Jones, Simon L.},
    booktitle = {Proceedings of the ACM SIGPLAN 1994 conference on Programming language design and implementation},
    citeulike-article-id = {4889},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.144.2237\&\#38;rep=rep1\&\#38;type=pdf},
    citeulike-linkout-1 = {http://research.microsoft.com/en-us/um/people/simonpj/papers/lazy-functional-state-threads.ps.Z},
    citeulike-linkout-2 = {http://portal.acm.org/citation.cfm?id=178246},
    citeulike-linkout-3 = {http://dx.doi.org/10.1145/178243.178246},
    isbn = {0-89791-662-X},
    keywords = {haskell, language, programming, state},
    location = {Orlando, Florida, United States},
    month = jun,
    number = {6},
    pages = {24--35},
    posted-at = {2012-01-31 03:34:50},
    priority = {2},
    publisher = {ACM},
    series = {PLDI '94},
    title = {{Lazy functional state threads}},
    volume = {29},
    year = {1994}
}

@article{Rubin1984Bayesianly,
    abstract = {{A common reaction among applied statisticians is that the Bayesian statistician's energies in an applied problem must be directed at the a priori elicitation of one model specification from which an optimal design and all inferences follow automatically by applying Bayes's theorem to calculate conditional distributions of unknowns given knowns. I feel, however, that the applied Bayesian statistician's tool-kit should be more extensive and include tools that may be usefully labeled frequency calculations. Three types of Bayesianly justifiable and relevant frequency calculations are presented using examples to convey their use for the applied statistician.}},
    author = {Rubin, Donald B.},
    citeulike-article-id = {213404},
    citeulike-linkout-0 = {http://www.jstor.org/stable/2240995},
    issn = {00905364},
    journal = {The Annals of Statistics},
    keywords = {bayesian, statistics},
    number = {4},
    pages = {1151--1172},
    posted-at = {2012-01-17 17:05:26},
    priority = {2},
    publisher = {Institute of Mathematical Statistics},
    title = {{Bayesianly Justifiable and Relevant Frequency Calculations for the Applies Statistician}},
    volume = {12},
    year = {1984}
}

@article{Reshef2011Detecting,
    abstract = {{
                Identifying interesting relationships between pairs of variables in large data sets is increasingly important. Here, we present a measure of dependence for two-variable relationships: the maximal information coefficient (MIC). MIC captures a wide range of associations both functional and not, and for functional relationships provides a score that roughly equals the coefficient of determination (R(2)) of the data relative to the regression function. MIC belongs to a larger class of maximal information-based nonparametric exploration (MINE) statistics for identifying and classifying relationships. We apply MIC and MINE to data sets in global health, gene expression, major-league baseball, and the human gut microbiota and identify known and novel relationships.
            }},
    author = {Reshef, David N. and Reshef, Yakir A. and Finucane, Hilary K. and Grossman, Sharon R. and McVean, Gilean and Turnbaugh, Peter J. and Lander, Eric S. and Mitzenmacher, Michael and Sabeti, Pardis C.},
    citeulike-article-id = {10132366},
    citeulike-linkout-0 = {http://dx.doi.org/10.1126/science.1205438},
    citeulike-linkout-1 = {http://www.sciencemag.org/content/334/6062/1518.abstract},
    citeulike-linkout-2 = {http://www.sciencemag.org/content/334/6062/1518.full.pdf},
    citeulike-linkout-3 = {http://www.sciencemag.org/cgi/content/abstract/334/6062/1518},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/22174245},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=22174245},
    day = {16},
    issn = {1095-9203},
    journal = {Science},
    keywords = {correlation, nonlinear},
    month = dec,
    number = {6062},
    pages = {1518--1524},
    pmid = {22174245},
    posted-at = {2012-01-17 16:41:44},
    priority = {2},
    publisher = {American Association for the Advancement of Science},
    title = {{Detecting Novel Associations in Large Data Sets}},
    volume = {334},
    year = {2011}
}

@article{Boyd2011Comparing,
    abstract = {{We compare seven different strategies for computing spectrally-accurate approximations or differential equation solutions in a disk. Separation of variables for the Laplace operator yields an analytic solution as a Fourier–Bessel series, but this usually converges at an algebraic (sub-spectral) rate. The cylindrical Robert functions converge geometrically but are horribly ill-conditioned. The Zernike and Logan–Shepp polynomials span the same space, that of Cartesian polynomials of a given total degree, but the former allows partial factorization whereas the latter basis facilitates an efficient algorithm for solving the Poisson equation. The Zernike polynomials were independently rediscovered several times as the product of one-sided Jacobi polynomials in radius with a Fourier series in \^{I}¸. Generically, the Zernike basis requires only half as many degrees of freedom to represent a complicated function on the disk as does a Chebyshev–Fourier basis, but the latter has the great advantage of being summed and interpolated entirely by the Fast Fourier Transform instead of the slower matrix multiplication transforms needed in radius by the Zernike basis. Conformally mapping a square to the disk and employing a bivariate Chebyshev expansion on the square is spectrally accurate, but clustering of grid points near the four singularities of the mapping makes this method less efficient than the rest, meritorious only as a quick-and-dirty way to adapt a solver-for-the-square to the disk. Radial basis functions can match the best other spectral methods in accuracy, but require slow non-tensor interpolation and summation methods. There is no single  ” best” basis for the disk, but we have laid out the merits and flaws of each spectral option.}},
    author = {Boyd, John P. and Yu, Fu},
    citeulike-article-id = {8341546},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jcp.2010.11.011},
    day = {20},
    issn = {00219991},
    journal = {Journal of Computational Physics},
    keywords = {analysis, interpolation, numerical, spectral},
    month = feb,
    number = {4},
    pages = {1408--1438},
    posted-at = {2012-01-17 16:21:31},
    priority = {2},
    title = {{Comparing seven spectral methods for interpolation and for solving the Poisson equation in a disk: Zernike polynomials, Logan–Shepp ridge polynomials, Chebyshev–Fourier Series, cylindrical Robert functions, Bessel–Fourier expansions, square-to-disk conformal mapping and radial basis functions}},
    volume = {230},
    year = {2011}
}

@article{Gelman2011Philosophy,
    abstract = {{A substantial school in the philosophy of science identifies Bayesian
inference with inductive inference and even rationality as such, and seems to
be strengthened by the rise and practical success of Bayesian statistics. We
argue that the most successful forms of Bayesian statistics do not actually
support that particular philosophy but rather accord much better with
sophisticated forms of hypothetico-deductivism. We examine the actual role
played by prior distributions in Bayesian models, and the crucial aspects of
model checking and model revision, which fall outside the scope of Bayesian
confirmation theory. We draw on the literature on the consistency of Bayesian
updating and also on our experience of applied work in social science.


Clarity about these matters should benefit not just philosophy of science,
but also statistical practice. At best, the inductivist view has encouraged
researchers to fit and compare models without checking them; at worst,
theorists have actively discouraged practitioners from performing model
checking because it does not fit into their framework.}},
    archivePrefix = {arXiv},
    author = {Gelman, Andrew and Shalizi, Cosma R.},
    citeulike-article-id = {7347615},
    citeulike-linkout-0 = {http://arxiv.org/abs/1006.3868},
    citeulike-linkout-1 = {http://arxiv.org/pdf/1006.3868},
    day = {28},
    eprint = {1006.3868},
    keywords = {bayesian, learning, machine},
    month = jun,
    posted-at = {2012-01-17 16:13:14},
    priority = {2},
    title = {{Philosophy and the practice of Bayesian statistics}},
    year = {2011}
}

@book{Li2001Markov,
    abstract = {{An abstract is not available.}},
    address = {Secaucus, NJ, USA},
    author = {Li, Stan Z.},
    citeulike-article-id = {961316},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=381180},
    isbn = {4-431-70309-8},
    keywords = {mrf},
    posted-at = {2012-05-15 18:58:07},
    priority = {2},
    publisher = {Springer-Verlag New York, Inc.},
    title = {{Markov random field modeling in image analysis}},
    url = {http://portal.acm.org/citation.cfm?id=381180},
    year = {2001}
}

@book{Bishop2006Pattern,
    author = {Bishop, C. M.},
    chapter = {5.6},
    citeulike-article-id = {3385885},
    journal = {Springer},
    keywords = {book, ml},
    pages = {272--277},
    posted-at = {2012-05-15 19:27:33},
    priority = {2},
    title = {{Pattern Recognition and Machine Learning}},
    year = {2006}
}

@inproceedings{Krahenbuhl2011Efficient,
    abstract = {{Most state-of-the-art techniques for multi-class image segmentation and labeling use conditional random fields defined over pixels or image regions. While region-level models often feature dense pairwise connectivity, pixel-level models are considerably larger and have only permitted sparse graph structures. In this paper, we consider fully connected CRF models defined on the complete set of pixels in an image. The resulting graphs have billions of edges, making traditional inference algorithms impractical. Our main contribution is a highly efficient approximate inference algorithm for fully connected CRF models in which the pairwise edge potentials are defined by a linear combination of Gaussian kernels. Our experiments demonstrate that dense connectivity at the pixel level substantially improves segmentation and labeling accuracy.}},
    author = {Kr\"{a}henb\"{u}hl, Philipp and Koltun, Vladlen},
    booktitle = {Advances in Neural Information Processing Systems (NIPS 2011)},
    citeulike-article-id = {10348477},
    citeulike-linkout-0 = {http://vladlen.org/publications/efficient-inference-in-fully-connected-crfs-with-gaussian-edge-potentials/},
    keywords = {crf, gaussian, inference, mrf},
    month = dec,
    posted-at = {2012-05-15 19:32:42},
    priority = {2},
    title = {{Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials}},
    url = {http://vladlen.org/publications/efficient-inference-in-fully-connected-crfs-with-gaussian-edge-potentials/},
    year = {2011}
}

@book{Szeliski2010,
    author = {Szeliski, Richard},
    citeulike-article-id = {8065760},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1848829345},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/1848829345},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/1848829345},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/1848829345},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/1848829345/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/1848829345},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/1848829345},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN1848829345},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=1848829345\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/1848829345},
    day = {24},
    edition = {1st Edition.},
    howpublished = {Hardcover},
    isbn = {1848829345},
    keywords = {book, cv},
    month = nov,
    posted-at = {2012-05-15 20:52:36},
    priority = {2},
    publisher = {Springer},
    title = {{Computer Vision: Algorithms and Applications (Texts in Computer Science)}},
    url = {http://www.worldcat.org/isbn/1848829345},
    year = {2010}
}

@article{Borgefors1986Distance,
    abstract = {{An abstract is not available.}},
    address = {San Diego, CA, USA},
    author = {Borgefors, Gunilla},
    citeulike-article-id = {833062},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=17147},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/S0734-189X(86)80047-0},
    doi = {10.1016/S0734-189X(86)80047-0},
    issn = {0734-189X},
    journal = {Comput. Vision Graph. Image Process.},
    keywords = {distance\_transform},
    month = jun,
    number = {3},
    pages = {344--371},
    posted-at = {2012-05-15 20:59:11},
    priority = {2},
    publisher = {Academic Press Professional, Inc.},
    title = {{Distance transformations in digital images}},
    url = {http://dx.doi.org/10.1016/S0734-189X(86)80047-0},
    volume = {34},
    year = {1986}
}

@inproceedings{Felzenszwalb2004Distance,
    abstract = {{This paper provides linear-time algorithms for solving a class of minimization problems in-volving a cost function with both local and spatial terms. These problems can be viewed as a generalization of classical distance transforms of binary images, where the binary image is replaced by an arbitrary sampled function. Alternatively they can be viewed in terms of the minimum convolution of two functions, which is an important operation in grayscale mor-phology. A useful consequence of our techniques is a simple, fast method for computing the Euclidean distance transform of a binary image. The methods are also applicable to Viterbi decoding, belief propagation and optimal control. 1}},
    author = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
    booktitle = {Cornell Computing and Information Science},
    citeulike-article-id = {10611780},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.78.4312},
    keywords = {distance\_transform, transform},
    posted-at = {2012-04-27 01:17:15},
    priority = {2},
    title = {{Distance transforms of sampled functions}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.78.4312},
    year = {2004}
}

