\documentclass{article} % For LaTeX2e
\usepackage{nips12submit_e,times}
\usepackage{natbib}
\usepackage[pdftex]{graphicx}
%\documentstyle[nips12submit_09,times,art10]{article} % For LaTeX 2.09


\title{Binary Separation on Heterogeneous Image}

\author{
Fisher Yu \\
\texttt{fy@princeton.edu}
\And
Nanxi Kang \\
\texttt{nkang@princeton.edu} 
\And
Siyu Liu\\
\texttt{siyuliu@princeton.edu}
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\section{Introduction}

In computer vision, image segmentation is a process of partitioning an image into several pixel groups. The pixels in each group should have something in common, such as color, intensity or texture. The goal of image segmentation is to change the representation of an image into something meaningful and easy to understand. Image segmentation is one of the oldest and most widely studied problems. It is typically used to locate objects and boundaries in an image. An interesting application of image segmentation is to track facial features or objects of significance in a performance-driven animation. This helps to better compress the animation without loss of important information.

Particularly, how to partition an image into two segments: ``foreground'' and ``background'' is of special interest. Earlier techniques focused on finding the boundary curves between the objects and background. The algorithms include snakes~\citep{Kass1988snakes}, active contours~\citep{Isard1998condensation}, geodesic active contours~\citep{Caselles1995geodesic} and so on. A recent new approach by~\citet{Boykov2006graph} demonstrates a great potential for solving this problem. The approach replies on some manual sketchy on the original image. To be specific, a user draws a few red strokes in the foreground objects and a few blue ones in the background. Therefore, the algorithm gets some extra information about the background and foreground before doing image segmentation. Though the strokes might not be quite accurate, yet it indeed provides some useful information.   





There are snakes (Kass et al., 1988; Cohen, 1991), active contours (Isard and Blake, 1998), geodesic active contours (Caselles et al., 1997; Yezzi et al., 1997), “shortest path” tech- niques (Mortensen and Barrett, 1998; Falca ̃o et al., 1998) and many other examples of methods for par- titioning an image into two segments: “object” and “background”. 

The result of image segmentation is either a set of segments that cover the whole image, or a set of contours which separate the segments.

Image segmentation has many useful applications. For example, 

 Earlier techniques include algorithm based active contours, region splitting and merging, and mean shift.



\section{Data}
We got our data from Google street view team and processed it to use
the images in our project. The data was collected by a car equiped
with 8 cameras and 3 laser scanners. Each of the laser scanner can scan 180 degree 2D
plane at each time. Two of the laser scanners scanned vertically and
the third one scanned horizontally. As the car moved, the car
positions were recored by global positioning system. Those positions
were adjusted by the scans of the horizontal laser scanner using SLAM
(Simultaneous localization and mapping) techniques to get the best
precision. The 3D position of each laser scan point can be
estimated based on the relative position between the car and laser
scanners and therefore a 3D point cloud can be built from the scans of
the vertical laser scanners. At the same time, the eight
cameras were taking pictures as the car moved. Although the cameras
were well calibrated, the images were taken by rolling shutters and
there are errors in terms of image projection model if we assume each
image were taken in a pinhole model.

Given the 3D point cloud and images, we project the points into the
images with the estimated point positions, camera poses and projection
matrices. Then we can get images like Figure~\ref{fig-data_image}.

\begin{figure}[h]
\begin{center}
\includegraphics[height=0.5\linewidth]{./fig/image_sample.png}
\end{center}
\caption{An image with 3D points projected into it.}
\label{fig-data_image}
\end{figure}

In Figure~\ref{fig-data_image}, the black dots are the projections of
the 3D points in this image. As you can see, due to all kinds of
errors mentioned above, the 3D projections and the images are not well
aligned and we can't segment the images directly based on the depth of
the 3D scan points. In this project, we want to find the contour
between the background (the sky area) and foreground (all the objects
appears in the image, including roads and buildings). The models and
computing issue will be discussed in the methods section.

\section{Methods}

We propose to formulate the background and foreground separation
problem as labeling problem. We assign each pixel a binary latent
variable representing the category of the pixel. For each
segmentation (foreground or background), we plan to use Gaussian Mixture Model to model the
distribution of the colors. If the distribution of the pixel colors
are independent, we can use the mixture model together with EM
(Expectation-Maximization) algorithm to solve the assignment of labels
directly. However, this method would not work well because we would
get very noisy label assignment to the pixels. The essential problem
is that there is interaction between adjacent pixels. If all the
neighbors of a pixel are labeled foreground, it is more possible that
this pixel also belongs to foreground. We plan to
use MRF(Markov Random Field) to model this idea. As mentioned in
introduction, this model is widely used by a lot of works. A good
survey is in~\citep{Szeliski2008Comparative}.

\begin{figure}[ht]
\begin{center}
\includegraphics[height=0.5\linewidth]{./fig/graphical_model.png}
\end{center}
\caption{model}
\label{fig-graphical_model}
\end{figure}

The graphical representation of our model is shown in
Figure~\ref{fig-graphical_model}.



\section{Evaluation}


\bibliography{proposal}
\bibliographystyle{abbrvnat}


\end{document}
